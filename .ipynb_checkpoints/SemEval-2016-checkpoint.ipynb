{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6651cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14ca5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Target  \\\n",
      "0                      Atheism   \n",
      "1                      Atheism   \n",
      "2                      Atheism   \n",
      "3                      Atheism   \n",
      "4                      Atheism   \n",
      "...                        ...   \n",
      "2809  Legalization of Abortion   \n",
      "2810  Legalization of Abortion   \n",
      "2811  Legalization of Abortion   \n",
      "2812  Legalization of Abortion   \n",
      "2813  Legalization of Abortion   \n",
      "\n",
      "                                                  Tweet   Stance  \n",
      "0     dear lord thank u for all of ur blessings forg...  AGAINST  \n",
      "1     Blessed are the peacemakers, for they shall be...  AGAINST  \n",
      "2     I am not conformed to this world. I am transfo...  AGAINST  \n",
      "3     Salah should be prayed with #focus and #unders...  AGAINST  \n",
      "4     And stay in your houses and do not display you...  AGAINST  \n",
      "...                                                 ...      ...  \n",
      "2809  There's a law protecting unborn eagles, but no...  AGAINST  \n",
      "2810  I am 1 in 3... I have had an abortion #Abortio...  AGAINST  \n",
      "2811  How dare you say my sexual preference is a cho...  AGAINST  \n",
      "2812  Equal rights for those 'born that way', no rig...  AGAINST  \n",
      "2813  #POTUS seals his legacy w/ 1/2 doz wins. The #...  AGAINST  \n",
      "\n",
      "[2814 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tweets = []\n",
    "with open('trainingdata-all-annotations.txt','r', encoding = 'iso-8859-1') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        tweets.append(line.split('\\t'))\n",
    "        \n",
    "mat = np.array(tweets)\n",
    "mat = np.delete(mat, 0, axis=0)\n",
    "\n",
    "df_training = pd.DataFrame(mat, columns = ['ID','Target','Tweet','Stance','Opinion towards', 'Sentiment'])\n",
    "df_training = df_training.drop(['ID','Opinion towards', 'Sentiment'], axis=1)\n",
    "\n",
    "print(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d924c881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Target  \\\n",
      "0   Climate Change is a Real Concern   \n",
      "1   Climate Change is a Real Concern   \n",
      "2   Climate Change is a Real Concern   \n",
      "3   Climate Change is a Real Concern   \n",
      "4   Climate Change is a Real Concern   \n",
      "..                               ...   \n",
      "57                 Feminist Movement   \n",
      "58                 Feminist Movement   \n",
      "59                 Feminist Movement   \n",
      "60                 Feminist Movement   \n",
      "61                 Feminist Movement   \n",
      "\n",
      "                                                Tweet   Stance  \n",
      "0   \"Your CARBON FOOTPRINT will now be used to CON...  AGAINST  \n",
      "1   We may reach a 1.5°C world in as little as 5 y...    FAVOR  \n",
      "2   \"Indeed, it is a \"\"genocidal narrative\"\" to bl...  AGAINST  \n",
      "3   \"Remember - the wildfires, the droughts, the h...    FAVOR  \n",
      "4   The NYC mayor Adams has declared war on meat b...  AGAINST  \n",
      "..                                                ...      ...  \n",
      "57  “I love myself when I am laughing. . . and the...    FAVOR  \n",
      "58  My bad-ass feminist friend and I are seeing a ...    FAVOR  \n",
      "59  Trans rights don’t cancel out my woman’s right...    FAVOR  \n",
      "60  This is the true definition of #feminism today...  AGAINST  \n",
      "61  “(…) and still there’s the demonization of the...    FAVOR  \n",
      "\n",
      "[62 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "with open('additional-tweets.txt','r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        tweets.append(line.split('\\t'))\n",
    "        \n",
    "mat = np.array(tweets)\n",
    "mat = np.delete(mat, 0, axis=0)\n",
    "\n",
    "df_testing = pd.DataFrame(mat, columns = ['Target','Tweet','Stance'])\n",
    "\n",
    "df_testing['Stance'] = [word[:-1] for word in df_testing['Stance']]\n",
    "\n",
    "print(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c80934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     AGAINST\n",
      "1       FAVOR\n",
      "2     AGAINST\n",
      "3       FAVOR\n",
      "4     AGAINST\n",
      "       ...   \n",
      "57      FAVOR\n",
      "58      FAVOR\n",
      "59      FAVOR\n",
      "60    AGAINST\n",
      "61      FAVOR\n",
      "Name: Stance, Length: 62, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_testing['Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72643e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31138bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Blessed are the peacemakers, for they shall be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I am not conformed to this world. I am transfo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Salah should be prayed with #focus and #unders...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>And stay in your houses and do not display you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                              Tweet  Stance\n",
       "0       0  dear lord thank u for all of ur blessings forg...       0\n",
       "1       0  Blessed are the peacemakers, for they shall be...       0\n",
       "2       0  I am not conformed to this world. I am transfo...       0\n",
       "3       0  Salah should be prayed with #focus and #unders...       0\n",
       "4       0  And stay in your houses and do not display you...       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "\n",
    "le1.fit(df_training['Stance'])\n",
    "df_training['Stance'] = le1.transform(df_training['Stance'])\n",
    "df_testing['Stance'] = le1.transform(df_testing['Stance'])\n",
    "\n",
    "le2.fit(df_training['Target'])\n",
    "df_training['Target'] = le2.transform(df_training['Target'])\n",
    "df_testing['Target'] = le2.transform(df_testing['Target'])\n",
    "print(len(df_training['Target']))\n",
    "\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ed1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_to_norm = ['Target']\n",
    "df_training[cols_to_norm] = MinMaxScaler().fit_transform(df_training[cols_to_norm])\n",
    "df_testing[cols_to_norm] = MinMaxScaler().fit_transform(df_testing[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c386a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98076f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7760\n"
     ]
    }
   ],
   "source": [
    "unique_words = set();\n",
    "for string in df_training['Tweet']:\n",
    "    words = stemming_tokenizer(string)\n",
    "    unique_words.update(words)\n",
    "for string in df_testing['Tweet']:\n",
    "    words = stemming_tokenizer(string)\n",
    "    unique_words.update(words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc9b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caryslekander/opt/anaconda3/envs/python38env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:382: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>--isaiah</th>\n",
       "      <th>--ronald</th>\n",
       "      <th>-2</th>\n",
       "      <th>-babi</th>\n",
       "      <th>-blais</th>\n",
       "      <th>-but</th>\n",
       "      <th>-care</th>\n",
       "      <th>-galatian</th>\n",
       "      <th>...</th>\n",
       "      <th>zerlinamaxwel</th>\n",
       "      <th>zero</th>\n",
       "      <th>zerofootprint</th>\n",
       "      <th>zip</th>\n",
       "      <th>zmanoj</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombieneith</th>\n",
       "      <th>zora</th>\n",
       "      <th>zubair</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -   --  --isaiah  --ronald   -2  -babi  -blais  -but  -care  -galatian  \\\n",
       "0  0.0  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0        0.0   \n",
       "1  0.0  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0        0.0   \n",
       "2  0.0  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0        0.0   \n",
       "3  0.0  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0        0.0   \n",
       "4  0.0  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0        0.0   \n",
       "\n",
       "   ...  zerlinamaxwel  zero  zerofootprint  zip  zmanoj  zoe  zombieneith  \\\n",
       "0  ...            0.0   0.0            0.0  0.0     0.0  0.0          0.0   \n",
       "1  ...            0.0   0.0            0.0  0.0     0.0  0.0          0.0   \n",
       "2  ...            0.0   0.0            0.0  0.0     0.0  0.0          0.0   \n",
       "3  ...            0.0   0.0            0.0  0.0     0.0  0.0          0.0   \n",
       "4  ...            0.0   0.0            0.0  0.0     0.0  0.0          0.0   \n",
       "\n",
       "   zora  zubair  Target  \n",
       "0   0.0     0.0     0.0  \n",
       "1   0.0     0.0     0.0  \n",
       "2   0.0     0.0     0.0  \n",
       "3   0.0     0.0     0.0  \n",
       "4   0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 7761 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer( stop_words = 'english', tokenizer=stemming_tokenizer, vocabulary=unique_words)\n",
    "\n",
    "# Compute the TF-IDF matrix\n",
    "training_tfidf = vectorizer.fit_transform(df_training['Tweet'])\n",
    "testing_tfidf = vectorizer.fit_transform(df_testing['Tweet'])\n",
    "\n",
    "X_train = pd.DataFrame(training_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "X_train['Target'] = df_training['Target']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42aabdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>--isaiah</th>\n",
       "      <th>--ronald</th>\n",
       "      <th>-2</th>\n",
       "      <th>-babi</th>\n",
       "      <th>-blais</th>\n",
       "      <th>-but</th>\n",
       "      <th>-care</th>\n",
       "      <th>-galatian</th>\n",
       "      <th>...</th>\n",
       "      <th>zerlinamaxwel</th>\n",
       "      <th>zero</th>\n",
       "      <th>zerofootprint</th>\n",
       "      <th>zip</th>\n",
       "      <th>zmanoj</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombieneith</th>\n",
       "      <th>zora</th>\n",
       "      <th>zubair</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.172256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          -   --  --isaiah  --ronald   -2  -babi  -blais  -but  -care  \\\n",
       "0  0.000000  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0   \n",
       "1  0.000000  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0   \n",
       "2  0.000000  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0   \n",
       "3  0.172256  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0   \n",
       "4  0.000000  0.0       0.0       0.0  0.0    0.0     0.0   0.0    0.0   \n",
       "\n",
       "   -galatian  ...  zerlinamaxwel  zero  zerofootprint  zip  zmanoj  zoe  \\\n",
       "0        0.0  ...            0.0   0.0            0.0  0.0     0.0  0.0   \n",
       "1        0.0  ...            0.0   0.0            0.0  0.0     0.0  0.0   \n",
       "2        0.0  ...            0.0   0.0            0.0  0.0     0.0  0.0   \n",
       "3        0.0  ...            0.0   0.0            0.0  0.0     0.0  0.0   \n",
       "4        0.0  ...            0.0   0.0            0.0  0.0     0.0  0.0   \n",
       "\n",
       "   zombieneith  zora  zubair  Target  \n",
       "0          0.0   0.0     0.0     0.5  \n",
       "1          0.0   0.0     0.0     0.5  \n",
       "2          0.0   0.0     0.0     0.5  \n",
       "3          0.0   0.0     0.0     0.5  \n",
       "4          0.0   0.0     0.0     0.5  \n",
       "\n",
       "[5 rows x 7761 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.DataFrame(testing_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "X_test['Target'] = df_testing['Target']\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd860311",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_training.Stance.astype(np.int32)\n",
    "y_test = df_testing.Stance.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e70db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    correct_favor = len(results[(results['Actual Stance']=='FAVOR') & (results['Predicted Stance']=='FAVOR')])\n",
    "    favor_perct = correct_favor / len(results[(results['Actual Stance']=='FAVOR')])\n",
    "    correct_against = len(results[(results['Actual Stance']=='AGAINST') & (results['Predicted Stance']=='AGAINST')])\n",
    "    against_perct = correct_against / len(results[(results['Actual Stance']=='AGAINST')])\n",
    "    #correct_none = len(results[(results['Actual Stance']=='NONE') & (results['Predicted Stance']=='NONE')])\n",
    "    #none_perct = correct_none / len(results[(results['Actual Stance']=='NONE')])\n",
    "    print(f\"F: {correct_favor},  {favor_perct*100}%\")\n",
    "    print(f\"A: {correct_against},  {against_perct*100}%\")\n",
    "    #print(f\"N: {correct_none},  {none_perct*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd123e9",
   "metadata": {},
   "source": [
    "# Basic Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f406e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ea98fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1535bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37850861, 0.32263038, 0.29886102],\n",
       "       [0.32711532, 0.48842393, 0.18446074],\n",
       "       [0.29732476, 0.3035147 , 0.39916054],\n",
       "       [0.29925505, 0.53493936, 0.16580559],\n",
       "       [0.31356269, 0.44140621, 0.2450311 ],\n",
       "       [0.22193109, 0.5545427 , 0.22352621],\n",
       "       [0.23158487, 0.60523366, 0.16318148],\n",
       "       [0.36469073, 0.44284924, 0.19246003],\n",
       "       [0.31879663, 0.44280167, 0.2384017 ],\n",
       "       [0.28602826, 0.48185826, 0.23211348],\n",
       "       [0.26358011, 0.66019734, 0.07622255],\n",
       "       [0.51613296, 0.36748263, 0.11638441],\n",
       "       [0.21550539, 0.61780819, 0.16668642],\n",
       "       [0.26585233, 0.4311006 , 0.30304707],\n",
       "       [0.33624236, 0.39400752, 0.26975012],\n",
       "       [0.21276277, 0.57782156, 0.20941567],\n",
       "       [0.24076347, 0.57209653, 0.18714   ],\n",
       "       [0.40577151, 0.48116959, 0.1130589 ],\n",
       "       [0.39420235, 0.33835824, 0.26743941],\n",
       "       [0.37896267, 0.31992989, 0.30110744],\n",
       "       [0.18573605, 0.52027534, 0.29398861],\n",
       "       [0.30873709, 0.55591447, 0.13534844],\n",
       "       [0.36666415, 0.31450655, 0.3188293 ],\n",
       "       [0.43488205, 0.37418656, 0.19093139],\n",
       "       [0.40412396, 0.40901828, 0.18685776],\n",
       "       [0.40088721, 0.22104673, 0.37806606],\n",
       "       [0.2668865 , 0.22010956, 0.51300394],\n",
       "       [0.41149805, 0.27423116, 0.3142708 ],\n",
       "       [0.34966403, 0.34542364, 0.30491233],\n",
       "       [0.30940837, 0.40972075, 0.28087088],\n",
       "       [0.24524464, 0.51306433, 0.24169103],\n",
       "       [0.25438691, 0.56706648, 0.1785466 ],\n",
       "       [0.38689737, 0.45008761, 0.16301502],\n",
       "       [0.61388215, 0.32842179, 0.05769606],\n",
       "       [0.33259934, 0.44307441, 0.22432625],\n",
       "       [0.33271167, 0.22788045, 0.43940788],\n",
       "       [0.45524332, 0.38848953, 0.15626715],\n",
       "       [0.31518351, 0.401362  , 0.2834545 ],\n",
       "       [0.40770422, 0.36633824, 0.22595754],\n",
       "       [0.50563929, 0.26790823, 0.22645248],\n",
       "       [0.54150896, 0.12965187, 0.32883916],\n",
       "       [0.57476259, 0.17170272, 0.25353468],\n",
       "       [0.38002967, 0.22727152, 0.39269881],\n",
       "       [0.47645068, 0.16211261, 0.36143671],\n",
       "       [0.5561902 , 0.16023724, 0.28357256],\n",
       "       [0.77894201, 0.12568569, 0.0953723 ],\n",
       "       [0.90875075, 0.08209776, 0.00915149],\n",
       "       [0.75353684, 0.12534146, 0.1211217 ],\n",
       "       [0.51218954, 0.42602348, 0.06178698],\n",
       "       [0.71239272, 0.19078849, 0.09681879],\n",
       "       [0.69267998, 0.13198719, 0.17533283],\n",
       "       [0.76818309, 0.17992328, 0.05189363],\n",
       "       [0.8892651 , 0.04908961, 0.06164528],\n",
       "       [0.61779872, 0.33927196, 0.04292932],\n",
       "       [0.45047753, 0.4252203 , 0.12430217],\n",
       "       [0.31845796, 0.49461799, 0.18692406],\n",
       "       [0.43554777, 0.54251887, 0.02193336],\n",
       "       [0.69531185, 0.19551383, 0.10917432],\n",
       "       [0.70342233, 0.11366895, 0.18290871],\n",
       "       [0.4018785 , 0.52315856, 0.07496294],\n",
       "       [0.51693474, 0.15369535, 0.32936991],\n",
       "       [0.51185288, 0.23688985, 0.25125727]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb9fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccefe8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5967741935483871"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9804e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_for_print = pd.DataFrame()\n",
    "results_for_print['Target'] = X_test['Target']\n",
    "results_for_print['Actual Stance'] = le1.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a68ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target Actual Stance Predicted Stance 1\n",
      "0      0.5       AGAINST            AGAINST\n",
      "1      0.5         FAVOR              FAVOR\n",
      "2      0.5       AGAINST               NONE\n",
      "3      0.5         FAVOR              FAVOR\n",
      "4      0.5       AGAINST              FAVOR\n",
      "5      0.5         FAVOR              FAVOR\n",
      "6      0.5         FAVOR              FAVOR\n",
      "7      0.5       AGAINST              FAVOR\n",
      "8      0.5       AGAINST              FAVOR\n",
      "9      0.5         FAVOR              FAVOR\n",
      "10     0.5       AGAINST              FAVOR\n",
      "11     0.5         FAVOR            AGAINST\n",
      "12     0.5         FAVOR              FAVOR\n",
      "13     0.5       AGAINST              FAVOR\n",
      "14     0.5         FAVOR              FAVOR\n",
      "15     0.5         FAVOR              FAVOR\n",
      "16     0.5         FAVOR              FAVOR\n",
      "17     0.5       AGAINST              FAVOR\n",
      "18     0.5       AGAINST            AGAINST\n",
      "19     0.5       AGAINST            AGAINST\n",
      "20     0.0       AGAINST              FAVOR\n",
      "21     0.0         FAVOR              FAVOR\n",
      "22     0.0         FAVOR            AGAINST\n",
      "23     0.0       AGAINST            AGAINST\n",
      "24     0.0         FAVOR              FAVOR\n",
      "25     0.0         FAVOR            AGAINST\n",
      "26     0.0       AGAINST               NONE\n",
      "27     0.0       AGAINST            AGAINST\n",
      "28     0.0       AGAINST            AGAINST\n",
      "29     0.0         FAVOR              FAVOR\n",
      "30     0.0         FAVOR              FAVOR\n",
      "31     0.0         FAVOR              FAVOR\n",
      "32     0.0         FAVOR              FAVOR\n",
      "33     0.0       AGAINST            AGAINST\n",
      "34     0.0         FAVOR              FAVOR\n",
      "35     0.0       AGAINST               NONE\n",
      "36     0.0         FAVOR            AGAINST\n",
      "37     0.0       AGAINST              FAVOR\n",
      "38     0.0         FAVOR            AGAINST\n",
      "39     0.0       AGAINST            AGAINST\n",
      "40     1.0       AGAINST            AGAINST\n",
      "41     1.0       AGAINST            AGAINST\n",
      "42     1.0       AGAINST               NONE\n",
      "43     1.0       AGAINST            AGAINST\n",
      "44     1.0       AGAINST            AGAINST\n",
      "45     1.0       AGAINST            AGAINST\n",
      "46     1.0         FAVOR            AGAINST\n",
      "47     1.0         FAVOR            AGAINST\n",
      "48     1.0         FAVOR            AGAINST\n",
      "49     1.0       AGAINST            AGAINST\n",
      "50     1.0         FAVOR            AGAINST\n",
      "51     1.0       AGAINST            AGAINST\n",
      "52     1.0       AGAINST            AGAINST\n",
      "53     1.0         FAVOR            AGAINST\n",
      "54     1.0       AGAINST            AGAINST\n",
      "55     1.0         FAVOR              FAVOR\n",
      "56     1.0         FAVOR              FAVOR\n",
      "57     1.0         FAVOR            AGAINST\n",
      "58     1.0         FAVOR            AGAINST\n",
      "59     1.0         FAVOR              FAVOR\n",
      "60     1.0       AGAINST            AGAINST\n",
      "61     1.0         FAVOR            AGAINST\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Target'] = X_test['Target']\n",
    "results['Actual Stance'] = le1.inverse_transform(y_test)\n",
    "results['Predicted Stance 1'] = le1.inverse_transform(y_hat)\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dedb709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 19,  59.375%\n",
      "A: 18,  60.0%\n"
     ]
    }
   ],
   "source": [
    "results_for_print['Predicted Stance'] = results['Predicted Stance 1']\n",
    "print_results(results_for_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7246d157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n",
      "F: 7,  63.63636363636363%\n",
      "A: 5,  55.55555555555556%\n",
      "Topic 3\n",
      "F: 9,  90.0%\n",
      "A: 3,  30.0%\n",
      "Topic 5\n",
      "F: 3,  27.27272727272727%\n",
      "A: 10,  90.9090909090909%\n"
     ]
    }
   ],
   "source": [
    "print(\"Topic 1\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 0.0)])\n",
    "#print(\"Topic 2\")\n",
    "#print_results(results_for_print[(results_for_print['Target'] == 0.25)])\n",
    "print(\"Topic 3\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 0.5)])\n",
    "#print(\"Topic 4\")\n",
    "#print_results(results_for_print[(results_for_print['Target'] == 0.75)])\n",
    "print(\"Topic 5\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "811e09b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  8  4]\n",
      " [13 19  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59        30\n",
      "           1       0.70      0.59      0.64        32\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60        62\n",
      "   macro avg       0.43      0.40      0.41        62\n",
      "weighted avg       0.64      0.60      0.62        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caryslekander/opt/anaconda3/envs/python38env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "print(mt.confusion_matrix(y_test,y_hat))\n",
    "print(mt.classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed90c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ee96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b942161",
   "metadata": {},
   "source": [
    "# Logistic Regression with Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f6cb773",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0, max_iter = 500, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "600905d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=500, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86b4b25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31034552, 0.35944742, 0.33020705],\n",
       "       [0.26604674, 0.53717958, 0.19677368],\n",
       "       [0.24046313, 0.32608643, 0.43345044],\n",
       "       [0.2416234 , 0.58343872, 0.17493788],\n",
       "       [0.25547092, 0.47755956, 0.26696953],\n",
       "       [0.18092234, 0.58280227, 0.2362754 ],\n",
       "       [0.19021025, 0.64083429, 0.16895546],\n",
       "       [0.29815039, 0.49597762, 0.20587199],\n",
       "       [0.25741285, 0.48549026, 0.25709689],\n",
       "       [0.23088947, 0.52167927, 0.24743126],\n",
       "       [0.21692788, 0.70435433, 0.07871779],\n",
       "       [0.44889054, 0.42165346, 0.129456  ],\n",
       "       [0.17651275, 0.64953725, 0.17395   ],\n",
       "       [0.21467489, 0.46558396, 0.31974116],\n",
       "       [0.27195319, 0.43279252, 0.29525429],\n",
       "       [0.16956687, 0.60938361, 0.22104952],\n",
       "       [0.19469586, 0.61106758, 0.19423656],\n",
       "       [0.3337807 , 0.54459716, 0.12162214],\n",
       "       [0.32180413, 0.38215666, 0.29603922],\n",
       "       [0.30793242, 0.35293538, 0.33913219],\n",
       "       [0.14696509, 0.54207811, 0.3109568 ],\n",
       "       [0.24721392, 0.60510609, 0.14767999],\n",
       "       [0.29719293, 0.34778702, 0.35502005],\n",
       "       [0.36217427, 0.42910006, 0.20872567],\n",
       "       [0.33115058, 0.46294106, 0.20590836],\n",
       "       [0.33097116, 0.24188628, 0.42714256],\n",
       "       [0.20973691, 0.24011172, 0.55015137],\n",
       "       [0.33536946, 0.3071442 , 0.35748634],\n",
       "       [0.28245111, 0.38275001, 0.33479889],\n",
       "       [0.24559491, 0.4484325 , 0.30597259],\n",
       "       [0.19431962, 0.5423644 , 0.26331597],\n",
       "       [0.19739462, 0.60887285, 0.19373254],\n",
       "       [0.31238473, 0.50787652, 0.17973875],\n",
       "       [0.55043643, 0.3866813 , 0.06288228],\n",
       "       [0.26406144, 0.49263042, 0.24330814],\n",
       "       [0.26912437, 0.24667599, 0.48419964],\n",
       "       [0.37890297, 0.44170585, 0.17939118],\n",
       "       [0.24970421, 0.4376322 , 0.3126636 ],\n",
       "       [0.33466036, 0.41452748, 0.25081217],\n",
       "       [0.42803774, 0.31102932, 0.26093294],\n",
       "       [0.46915572, 0.147657  , 0.38318727],\n",
       "       [0.50197808, 0.19974007, 0.29828185],\n",
       "       [0.30550729, 0.25633787, 0.43815485],\n",
       "       [0.4040474 , 0.18304867, 0.41290393],\n",
       "       [0.47945153, 0.18425447, 0.336294  ],\n",
       "       [0.74157222, 0.15089466, 0.10753313],\n",
       "       [0.89636795, 0.09556912, 0.00806293],\n",
       "       [0.7107693 , 0.15095589, 0.13827481],\n",
       "       [0.43979304, 0.49343131, 0.06677566],\n",
       "       [0.6597578 , 0.23122688, 0.10901532],\n",
       "       [0.63618571, 0.16098116, 0.20283313],\n",
       "       [0.72357149, 0.22194201, 0.05448649],\n",
       "       [0.87780428, 0.05487471, 0.06732101],\n",
       "       [0.55334028, 0.40125561, 0.04540411],\n",
       "       [0.37837514, 0.48811923, 0.13350563],\n",
       "       [0.2600378 , 0.54618319, 0.193779  ],\n",
       "       [0.3709363 , 0.60721562, 0.02184808],\n",
       "       [0.6363754 , 0.24066249, 0.12296211],\n",
       "       [0.65168586, 0.13512805, 0.21318609],\n",
       "       [0.33515971, 0.58363719, 0.08120309],\n",
       "       [0.44585684, 0.17654606, 0.3775971 ],\n",
       "       [0.43632553, 0.27800059, 0.28567388]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a83aeb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bfabe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5161290322580645"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41458e36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target Actual Stance Predicted Stance 1 Predicted Stance 2\n",
      "0      0.5       AGAINST            AGAINST              FAVOR\n",
      "1      0.5         FAVOR              FAVOR              FAVOR\n",
      "2      0.5       AGAINST               NONE               NONE\n",
      "3      0.5         FAVOR              FAVOR              FAVOR\n",
      "4      0.5       AGAINST              FAVOR              FAVOR\n",
      "5      0.5         FAVOR              FAVOR              FAVOR\n",
      "6      0.5         FAVOR              FAVOR              FAVOR\n",
      "7      0.5       AGAINST              FAVOR              FAVOR\n",
      "8      0.5       AGAINST              FAVOR              FAVOR\n",
      "9      0.5         FAVOR              FAVOR              FAVOR\n",
      "10     0.5       AGAINST              FAVOR              FAVOR\n",
      "11     0.5         FAVOR            AGAINST            AGAINST\n",
      "12     0.5         FAVOR              FAVOR              FAVOR\n",
      "13     0.5       AGAINST              FAVOR              FAVOR\n",
      "14     0.5         FAVOR              FAVOR              FAVOR\n",
      "15     0.5         FAVOR              FAVOR              FAVOR\n",
      "16     0.5         FAVOR              FAVOR              FAVOR\n",
      "17     0.5       AGAINST              FAVOR              FAVOR\n",
      "18     0.5       AGAINST            AGAINST              FAVOR\n",
      "19     0.5       AGAINST            AGAINST              FAVOR\n",
      "20     0.0       AGAINST              FAVOR              FAVOR\n",
      "21     0.0         FAVOR              FAVOR              FAVOR\n",
      "22     0.0         FAVOR            AGAINST               NONE\n",
      "23     0.0       AGAINST            AGAINST              FAVOR\n",
      "24     0.0         FAVOR              FAVOR              FAVOR\n",
      "25     0.0         FAVOR            AGAINST               NONE\n",
      "26     0.0       AGAINST               NONE               NONE\n",
      "27     0.0       AGAINST            AGAINST               NONE\n",
      "28     0.0       AGAINST            AGAINST              FAVOR\n",
      "29     0.0         FAVOR              FAVOR              FAVOR\n",
      "30     0.0         FAVOR              FAVOR              FAVOR\n",
      "31     0.0         FAVOR              FAVOR              FAVOR\n",
      "32     0.0         FAVOR              FAVOR              FAVOR\n",
      "33     0.0       AGAINST            AGAINST            AGAINST\n",
      "34     0.0         FAVOR              FAVOR              FAVOR\n",
      "35     0.0       AGAINST               NONE               NONE\n",
      "36     0.0         FAVOR            AGAINST              FAVOR\n",
      "37     0.0       AGAINST              FAVOR              FAVOR\n",
      "38     0.0         FAVOR            AGAINST              FAVOR\n",
      "39     0.0       AGAINST            AGAINST            AGAINST\n",
      "40     1.0       AGAINST            AGAINST            AGAINST\n",
      "41     1.0       AGAINST            AGAINST            AGAINST\n",
      "42     1.0       AGAINST               NONE               NONE\n",
      "43     1.0       AGAINST            AGAINST               NONE\n",
      "44     1.0       AGAINST            AGAINST            AGAINST\n",
      "45     1.0       AGAINST            AGAINST            AGAINST\n",
      "46     1.0         FAVOR            AGAINST            AGAINST\n",
      "47     1.0         FAVOR            AGAINST            AGAINST\n",
      "48     1.0         FAVOR            AGAINST              FAVOR\n",
      "49     1.0       AGAINST            AGAINST            AGAINST\n",
      "50     1.0         FAVOR            AGAINST            AGAINST\n",
      "51     1.0       AGAINST            AGAINST            AGAINST\n",
      "52     1.0       AGAINST            AGAINST            AGAINST\n",
      "53     1.0         FAVOR            AGAINST            AGAINST\n",
      "54     1.0       AGAINST            AGAINST              FAVOR\n",
      "55     1.0         FAVOR              FAVOR              FAVOR\n",
      "56     1.0         FAVOR              FAVOR              FAVOR\n",
      "57     1.0         FAVOR            AGAINST            AGAINST\n",
      "58     1.0         FAVOR            AGAINST            AGAINST\n",
      "59     1.0         FAVOR              FAVOR              FAVOR\n",
      "60     1.0       AGAINST            AGAINST            AGAINST\n",
      "61     1.0         FAVOR            AGAINST            AGAINST\n"
     ]
    }
   ],
   "source": [
    "results['Predicted Stance 2'] = le1.inverse_transform(y_hat)\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dc971a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 22,  68.75%\n",
      "A: 10,  33.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "results_for_print['Predicted Stance'] = results['Predicted Stance 2']\n",
    "print_results(results_for_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f98f0b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n",
      "F: 9,  81.81818181818183%\n",
      "A: 2,  22.22222222222222%\n",
      "Topic 3\n",
      "F: 9,  90.0%\n",
      "A: 0,  0.0%\n",
      "Topic 5\n",
      "F: 4,  36.36363636363637%\n",
      "A: 8,  72.72727272727273%\n"
     ]
    }
   ],
   "source": [
    "print(\"Topic 1\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 0.0)])\n",
    "#print(\"Topic 2\")\n",
    "#print_results(results_for_print[(results_for_print['Target'] == 0.25)])\n",
    "print(\"Topic 3\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 0.5)])\n",
    "#print(\"Topic 4\")\n",
    "#print_results(results_for_print[(results_for_print['Target'] == 0.75)])\n",
    "print(\"Topic 5\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f0f8b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 14  6]\n",
      " [ 8 22  2]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.33      0.42        30\n",
      "           1       0.61      0.69      0.65        32\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52        62\n",
      "   macro avg       0.39      0.34      0.35        62\n",
      "weighted avg       0.58      0.52      0.54        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caryslekander/opt/anaconda3/envs/python38env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "print(mt.confusion_matrix(y_test,y_hat))\n",
    "print(mt.classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b4258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62904ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ad43807",
   "metadata": {},
   "source": [
    "# Multi-Layer Percptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c4a077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b28b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0, size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_) # reshape to be W\n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden)\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2\n",
    "\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z): # no changes needed \n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "        \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term    \n",
    "    \n",
    "    def _feedforward(self, X, W1, W2, b1, b2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        W1: Weight matrix for input layer -> hidden layer.\n",
    "        W2: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a1-a3 : activations into layer (or output layer)\n",
    "        z1-z2 : layer inputs \n",
    "\n",
    "        \"\"\"\n",
    "        A1 = X.T\n",
    "        Z1 = W1 @ A1 + b1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        Z2 = W2 @ A2 + b2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C\n",
    "        gradW2 += W2 * self.l2_C\n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2, self.b1, self.b2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3767a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# just start with the vectorized version and minibatch\n",
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False, XY_test=None): #gotta be honest this one scared me so I didn't change anything yet\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2, self.b1, self.b2 = self._initialize_weights()\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        # get starting acc\n",
    "        self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "        # keep track of validation, if given\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "            self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2,\n",
    "                                                       self.b1,\n",
    "                                                       self.b2\n",
    "                                                      )\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                gradW1, gradW2, gradb1, gradb2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                self.W1 -= self.eta * gradW1\n",
    "                self.W2 -= self.eta * gradW2\n",
    "                self.b1 -= self.eta * gradb1\n",
    "                self.b2 -= self.eta * gradb2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e497f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _cost3(self,A4,Y_enc,W1,W2,W3): #not quite sure\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A4)+(1-Y_enc)*np.log(1-A4))))\n",
    "        L2_term = self._L2_reg3(self.l2_C, W1, W2, W3)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = (A3-Y_enc) # <- this is only line that changed\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C\n",
    "        gradW2 += W2 * self.l2_C\n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2\n",
    "    \n",
    "    def _get_gradient3(self, A1, A2, A3, A4, Z1, Z2, Z3, Y_enc, W1, W2, W3):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        #ahhhhhhhhhhhhhhhhhhhh idk\n",
    "        V2 = (A3-Y_enc) # <- this is only line that changed \n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW3 = V3 @ A3.T\n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb3 = np.sum(V3, axis=1).reshape((-1,1))\n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C\n",
    "        gradW2 += W2 * self.l2_C\n",
    "        gradW3 += W3 * self.l2_C\n",
    "\n",
    "        return gradW1, gradW2,gradW3, gradb1, gradb2, gradb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ca73652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPBetterInitial(TLPMiniBatchCrossEntropy):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights Glorot and He normalization.\"\"\"\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden + self.n_features_))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_))\n",
    "\n",
    "        # reduce the final layer magnitude in order to balance the size of the gradients\n",
    "        # between \n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden)) \n",
    "        \n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2\n",
    "    \n",
    "    def _initialize_weights3(self):\n",
    "        \"\"\"Initialize weights Glorot and He normalization.\"\"\"\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden + self.n_features_))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_))\n",
    "\n",
    "        # reduce the final layer magnitude in order to balance the size of the gradients\n",
    "        # between \n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden)) \n",
    "        \n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6b0aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def print_result(nn,X_train,y_train,X_test,y_test,title=\"\",color=\"red\"):\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(title,\":\")\n",
    "    yhat = nn.predict(X_train)\n",
    "    print('Resubstitution acc:',accuracy_score(y_train,yhat))\n",
    "    \n",
    "    yhat = nn.predict(X_test)\n",
    "    print('Validation acc:',accuracy_score(y_test,yhat))\n",
    "    \n",
    "    if hasattr(nn,'val_score_'):\n",
    "        plt.plot(range(len(nn.val_score_)), nn.val_score_, color=color,label=title)\n",
    "        plt.ylabel('Validation Accuracy')\n",
    "    else:\n",
    "        plt.plot(range(len(nn.score_)), nn.score_, color=color,label=title)\n",
    "        plt.ylabel('Resub Accuracy')\n",
    "        \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0e72dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = { 'n_hidden':30, \n",
    "         'C':0.1, 'epochs':75, 'eta':0.001, \n",
    "         'alpha':0.001, 'decrease_const':1e-5, 'minibatches':50,\n",
    "         'shuffle':True,'random_state':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5732d87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 500/500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Initial Data :\n",
      "Resubstitution acc: 0.8678038379530917\n",
      "Validation acc: 0.5806451612903226\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals['epochs'] = 500\n",
    "mlp = TLPBetterInitial(**vals)\n",
    "\n",
    "mlp.fit(X_train, y_train, print_progress=1, XY_test=(X_test, y_test))\n",
    "\n",
    "y_hat = print_result(mlp,X_train,y_train,X_test,y_test,title=\"Initial Data\",color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29921b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target Actual Stance Predicted Stance 1 Predicted Stance 2  \\\n",
      "0      0.5       AGAINST            AGAINST              FAVOR   \n",
      "1      0.5         FAVOR              FAVOR              FAVOR   \n",
      "2      0.5       AGAINST               NONE               NONE   \n",
      "3      0.5         FAVOR              FAVOR              FAVOR   \n",
      "4      0.5       AGAINST              FAVOR              FAVOR   \n",
      "5      0.5         FAVOR              FAVOR              FAVOR   \n",
      "6      0.5         FAVOR              FAVOR              FAVOR   \n",
      "7      0.5       AGAINST              FAVOR              FAVOR   \n",
      "8      0.5       AGAINST              FAVOR              FAVOR   \n",
      "9      0.5         FAVOR              FAVOR              FAVOR   \n",
      "10     0.5       AGAINST              FAVOR              FAVOR   \n",
      "11     0.5         FAVOR            AGAINST            AGAINST   \n",
      "12     0.5         FAVOR              FAVOR              FAVOR   \n",
      "13     0.5       AGAINST              FAVOR              FAVOR   \n",
      "14     0.5         FAVOR              FAVOR              FAVOR   \n",
      "15     0.5         FAVOR              FAVOR              FAVOR   \n",
      "16     0.5         FAVOR              FAVOR              FAVOR   \n",
      "17     0.5       AGAINST              FAVOR              FAVOR   \n",
      "18     0.5       AGAINST            AGAINST              FAVOR   \n",
      "19     0.5       AGAINST            AGAINST              FAVOR   \n",
      "20     0.0       AGAINST              FAVOR              FAVOR   \n",
      "21     0.0         FAVOR              FAVOR              FAVOR   \n",
      "22     0.0         FAVOR            AGAINST               NONE   \n",
      "23     0.0       AGAINST            AGAINST              FAVOR   \n",
      "24     0.0         FAVOR              FAVOR              FAVOR   \n",
      "25     0.0         FAVOR            AGAINST               NONE   \n",
      "26     0.0       AGAINST               NONE               NONE   \n",
      "27     0.0       AGAINST            AGAINST               NONE   \n",
      "28     0.0       AGAINST            AGAINST              FAVOR   \n",
      "29     0.0         FAVOR              FAVOR              FAVOR   \n",
      "30     0.0         FAVOR              FAVOR              FAVOR   \n",
      "31     0.0         FAVOR              FAVOR              FAVOR   \n",
      "32     0.0         FAVOR              FAVOR              FAVOR   \n",
      "33     0.0       AGAINST            AGAINST            AGAINST   \n",
      "34     0.0         FAVOR              FAVOR              FAVOR   \n",
      "35     0.0       AGAINST               NONE               NONE   \n",
      "36     0.0         FAVOR            AGAINST              FAVOR   \n",
      "37     0.0       AGAINST              FAVOR              FAVOR   \n",
      "38     0.0         FAVOR            AGAINST              FAVOR   \n",
      "39     0.0       AGAINST            AGAINST            AGAINST   \n",
      "40     1.0       AGAINST            AGAINST            AGAINST   \n",
      "41     1.0       AGAINST            AGAINST            AGAINST   \n",
      "42     1.0       AGAINST               NONE               NONE   \n",
      "43     1.0       AGAINST            AGAINST               NONE   \n",
      "44     1.0       AGAINST            AGAINST            AGAINST   \n",
      "45     1.0       AGAINST            AGAINST            AGAINST   \n",
      "46     1.0         FAVOR            AGAINST            AGAINST   \n",
      "47     1.0         FAVOR            AGAINST            AGAINST   \n",
      "48     1.0         FAVOR            AGAINST              FAVOR   \n",
      "49     1.0       AGAINST            AGAINST            AGAINST   \n",
      "50     1.0         FAVOR            AGAINST            AGAINST   \n",
      "51     1.0       AGAINST            AGAINST            AGAINST   \n",
      "52     1.0       AGAINST            AGAINST            AGAINST   \n",
      "53     1.0         FAVOR            AGAINST            AGAINST   \n",
      "54     1.0       AGAINST            AGAINST              FAVOR   \n",
      "55     1.0         FAVOR              FAVOR              FAVOR   \n",
      "56     1.0         FAVOR              FAVOR              FAVOR   \n",
      "57     1.0         FAVOR            AGAINST            AGAINST   \n",
      "58     1.0         FAVOR            AGAINST            AGAINST   \n",
      "59     1.0         FAVOR              FAVOR              FAVOR   \n",
      "60     1.0       AGAINST            AGAINST            AGAINST   \n",
      "61     1.0         FAVOR            AGAINST            AGAINST   \n",
      "\n",
      "   Predicted Stance 3  \n",
      "0             AGAINST  \n",
      "1               FAVOR  \n",
      "2                NONE  \n",
      "3               FAVOR  \n",
      "4               FAVOR  \n",
      "5               FAVOR  \n",
      "6               FAVOR  \n",
      "7               FAVOR  \n",
      "8               FAVOR  \n",
      "9               FAVOR  \n",
      "10              FAVOR  \n",
      "11            AGAINST  \n",
      "12              FAVOR  \n",
      "13              FAVOR  \n",
      "14              FAVOR  \n",
      "15              FAVOR  \n",
      "16              FAVOR  \n",
      "17              FAVOR  \n",
      "18            AGAINST  \n",
      "19            AGAINST  \n",
      "20              FAVOR  \n",
      "21              FAVOR  \n",
      "22            AGAINST  \n",
      "23            AGAINST  \n",
      "24            AGAINST  \n",
      "25            AGAINST  \n",
      "26               NONE  \n",
      "27            AGAINST  \n",
      "28            AGAINST  \n",
      "29              FAVOR  \n",
      "30              FAVOR  \n",
      "31              FAVOR  \n",
      "32              FAVOR  \n",
      "33            AGAINST  \n",
      "34              FAVOR  \n",
      "35               NONE  \n",
      "36            AGAINST  \n",
      "37              FAVOR  \n",
      "38            AGAINST  \n",
      "39            AGAINST  \n",
      "40            AGAINST  \n",
      "41            AGAINST  \n",
      "42               NONE  \n",
      "43            AGAINST  \n",
      "44            AGAINST  \n",
      "45            AGAINST  \n",
      "46            AGAINST  \n",
      "47            AGAINST  \n",
      "48            AGAINST  \n",
      "49            AGAINST  \n",
      "50            AGAINST  \n",
      "51            AGAINST  \n",
      "52            AGAINST  \n",
      "53            AGAINST  \n",
      "54            AGAINST  \n",
      "55              FAVOR  \n",
      "56              FAVOR  \n",
      "57            AGAINST  \n",
      "58            AGAINST  \n",
      "59              FAVOR  \n",
      "60            AGAINST  \n",
      "61            AGAINST  \n"
     ]
    }
   ],
   "source": [
    "results['Predicted Stance 3'] = le1.inverse_transform(y_hat)\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c07cd5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 18,  56.25%\n",
      "A: 18,  60.0%\n"
     ]
    }
   ],
   "source": [
    "results_for_print['Predicted Stance'] = results['Predicted Stance 3']\n",
    "print_results(results_for_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03ebe06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n",
      "F: 6,  54.54545454545454%\n",
      "A: 5,  55.55555555555556%\n",
      "Topic 3\n",
      "F: 9,  90.0%\n",
      "A: 3,  30.0%\n",
      "Topic 5\n",
      "F: 3,  27.27272727272727%\n",
      "A: 10,  90.9090909090909%\n"
     ]
    }
   ],
   "source": [
    "print(\"Topic 1\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 0.0)])\n",
    "#print(\"Topic 2\")\n",
    "#print_results(results_for_print[(results_for_print['Target'] == 0.25)])\n",
    "print(\"Topic 3\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 0.5)])\n",
    "#print(\"Topic 4\")\n",
    "#print_results(results_for_print[(results_for_print['Target'] == 0.75)])\n",
    "print(\"Topic 5\")\n",
    "print_results(results_for_print[(results_for_print['Target'] == 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45f0a415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  8  4]\n",
      " [14 18  0]\n",
      " [ 0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58        30\n",
      "           1       0.69      0.56      0.62        32\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.58        62\n",
      "   macro avg       0.42      0.39      0.40        62\n",
      "weighted avg       0.63      0.58      0.60        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caryslekander/opt/anaconda3/envs/python38env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "print(mt.confusion_matrix(y_test,y_hat))\n",
    "print(mt.classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ee119",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabcd8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34b41cc5",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68498244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 1\n",
      "F: 19,  59.375%\n",
      "A: 18,  60.0%\n",
      "[[18  8  4]\n",
      " [13 19  0]\n",
      " [ 0  0  0]]\n",
      "\n",
      "Logistic Regression 2\n",
      "F: 22,  68.75%\n",
      "A: 10,  33.33333333333333%\n",
      "[[10 14  6]\n",
      " [ 8 22  2]\n",
      " [ 0  0  0]]\n",
      "\n",
      "MLP\n",
      "F: 18,  56.25%\n",
      "A: 18,  60.0%\n",
      "[[18  8  4]\n",
      " [14 18  0]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression 1\")\n",
    "results_for_print['Predicted Stance'] = results['Predicted Stance 1']\n",
    "print_results(results_for_print)\n",
    "print(mt.confusion_matrix(y_test, le1.transform(results['Predicted Stance 1'])))\n",
    "print()\n",
    "print(\"Logistic Regression 2\")\n",
    "results_for_print['Predicted Stance'] = results['Predicted Stance 2']\n",
    "print_results(results_for_print)\n",
    "print(mt.confusion_matrix(y_test, le1.transform(results['Predicted Stance 2'])))\n",
    "print()\n",
    "print(\"MLP\")\n",
    "results_for_print['Predicted Stance'] = results['Predicted Stance 3']\n",
    "print_results(results_for_print)\n",
    "print(mt.confusion_matrix(y_test, le1.transform(results['Predicted Stance 3'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402093b5-aae3-40de-bd6a-bf967e93be1c",
   "metadata": {},
   "source": [
    "# One GRU Model For Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fd9e66-004c-4f2b-9bd4-0a24bffe1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77ff44-1de7-49ee-8e6d-c04a09a2639e",
   "metadata": {},
   "source": [
    "## Getting Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f207b05-2506-43bd-ac25-ca8c02a613c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Tweet   Stance\n",
      "0     dear lord thank u for all of ur blessings forg...  AGAINST\n",
      "1     Blessed are the peacemakers, for they shall be...  AGAINST\n",
      "2     I am not conformed to this world. I am transfo...  AGAINST\n",
      "3     Salah should be prayed with #focus and #unders...  AGAINST\n",
      "4     And stay in your houses and do not display you...  AGAINST\n",
      "...                                                 ...      ...\n",
      "2809  There's a law protecting unborn eagles, but no...  AGAINST\n",
      "2810  I am 1 in 3... I have had an abortion #Abortio...  AGAINST\n",
      "2811  How dare you say my sexual preference is a cho...  AGAINST\n",
      "2812  Equal rights for those 'born that way', no rig...  AGAINST\n",
      "2813  #POTUS seals his legacy w/ 1/2 doz wins. The #...  AGAINST\n",
      "\n",
      "[2814 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tweets = []\n",
    "with open('trainingdata-all-annotations.txt','r', encoding = 'iso-8859-1') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        tweets.append(line.split('\\t'))\n",
    "        \n",
    "mat = np.array(tweets)\n",
    "mat = np.delete(mat, 0, axis=0)\n",
    "\n",
    "df_full = pd.DataFrame(mat, columns = ['ID','Target','Tweet','Stance','Opinion towards', 'Sentiment'])\n",
    "df = df_full.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870bbeac-9d04-4dc2-bacb-611d586a574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGAINST    1342\n",
       "NONE        741\n",
       "FAVOR       731\n",
       "Name: Stance, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = df['Stance'].value_counts()\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baea6790-caa2-402e-9434-389c530283ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(df['Stance'])\n",
    "df['Stance'] = le1.transform(df['Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6886b4d1-f5b6-4d25-afc6-592e62f5608d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 0\n",
    "for i in df.Tweet:\n",
    "    if len(i.split()) > max_words:\n",
    "        max_words = len(i.split())\n",
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ebbe03-b279-4a5e-958e-f266aa3312fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 235 ms, total: 1.69 s\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "NUM_TOP_WORDS = None # use entire vocabulary!\n",
    "MAX_ART_LEN = 40 # maximum and minimum number of words\n",
    "\n",
    "#tokenize the text\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(df.Tweet)\n",
    "# save as sequences with integers replacing words\n",
    "sequences = tokenizer.texts_to_sequences(df.Tweet)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_train = df.Stance.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d6c2eb-39f1-4232-972a-c9a617c09355",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe = keras.utils.to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99bc0872-a433-4b4e-9507-5ac3e09839ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Embedding Shape: (9273, 100) \n",
      " Total words found: 6635 \n",
      " Percentage: 71.55181710341853\n",
      "CPU times: user 5.89 s, sys: 157 ms, total: 6.04 s\n",
      "Wall time: 6.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBED_SIZE = 100\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('/Users/caryslekander/Documents/School2022-2023/NLP/NLP-Project2/large_data/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "found_words = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be ALL-ZEROS\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        found_words = found_words+1\n",
    "\n",
    "print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
    "      \"Total words found:\",found_words, \"\\n\",\n",
    "      \"Percentage:\",100*found_words/embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1671c0-0ee7-42ea-bb45-2b7354f13bad",
   "metadata": {},
   "source": [
    "## Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "314768db-2cd9-4c55-b84a-1bf79a2047bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, GRU\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c40d2e7-b380-43fd-8922-05277fef7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this embedding now\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57451915-3c0d-4c50-89c8-62d1dfda7579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 100)           927300    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100)               60600     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 988,203\n",
      "Trainable params: 60,903\n",
      "Non-trainable params: 927,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 12:17:48.066444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "gru = Sequential()\n",
    "gru.add(embedding_layer)\n",
    "gru.add(GRU(100,dropout=0.2, recurrent_dropout=0.3))\n",
    "gru.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "print(gru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af2d9465-a5d0-48e7-8e5e-ed29a855e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy', keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd316c83-b5b3-4610-94ac-6a3ee335cb6e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 2s 25ms/step - loss: 0.6102 - accuracy: 0.4879 - recall: 0.2193\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.5831 - accuracy: 0.5203 - recall: 0.2839\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.5673 - accuracy: 0.5441 - recall: 0.3308\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.5498 - accuracy: 0.5561 - recall: 0.3895\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.5365 - accuracy: 0.5814 - recall: 0.4218\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.5306 - accuracy: 0.5888 - recall: 0.4542\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.5177 - accuracy: 0.5999 - recall: 0.4716\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.5099 - accuracy: 0.6098 - recall: 0.4865\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.5017 - accuracy: 0.6244 - recall: 0.4993\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4912 - accuracy: 0.6372 - recall: 0.5235\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4863 - accuracy: 0.6432 - recall: 0.5373\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4773 - accuracy: 0.6585 - recall: 0.5519\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4750 - accuracy: 0.6482 - recall: 0.5434\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.4683 - accuracy: 0.6588 - recall: 0.5554\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4584 - accuracy: 0.6631 - recall: 0.5679\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4526 - accuracy: 0.6731 - recall: 0.5888\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4416 - accuracy: 0.6986 - recall: 0.5988\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4363 - accuracy: 0.6855 - recall: 0.5991\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4329 - accuracy: 0.6955 - recall: 0.6116\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.4182 - accuracy: 0.6994 - recall: 0.6311\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4067 - accuracy: 0.7189 - recall: 0.6496\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.4087 - accuracy: 0.7161 - recall: 0.6340\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3936 - accuracy: 0.7310 - recall: 0.6638\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3839 - accuracy: 0.7370 - recall: 0.6681\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3798 - accuracy: 0.7381 - recall: 0.6830\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3723 - accuracy: 0.7377 - recall: 0.6745\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3655 - accuracy: 0.7480 - recall: 0.6855\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3526 - accuracy: 0.7669 - recall: 0.7122\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3497 - accuracy: 0.7669 - recall: 0.7150\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3428 - accuracy: 0.7708 - recall: 0.7164\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3302 - accuracy: 0.7804 - recall: 0.7321\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3273 - accuracy: 0.7857 - recall: 0.7377\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3181 - accuracy: 0.7889 - recall: 0.7441\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3083 - accuracy: 0.8006 - recall: 0.7640\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3014 - accuracy: 0.8056 - recall: 0.7679\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.2980 - accuracy: 0.8095 - recall: 0.7662\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.2926 - accuracy: 0.8063 - recall: 0.7647\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.2881 - accuracy: 0.8117 - recall: 0.7836\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.2772 - accuracy: 0.8223 - recall: 0.7793\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.2687 - accuracy: 0.8298 - recall: 0.7939\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2564 - accuracy: 0.8369 - recall: 0.8081\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.2582 - accuracy: 0.8387 - recall: 0.7996\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.2492 - accuracy: 0.8440 - recall: 0.8177\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2433 - accuracy: 0.8472 - recall: 0.8191\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2504 - accuracy: 0.8426 - recall: 0.8092\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2316 - accuracy: 0.8635 - recall: 0.8266\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2316 - accuracy: 0.8586 - recall: 0.8348\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2294 - accuracy: 0.8611 - recall: 0.8344\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2119 - accuracy: 0.8646 - recall: 0.8433\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2171 - accuracy: 0.8646 - recall: 0.8429\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2088 - accuracy: 0.8731 - recall: 0.8525\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1984 - accuracy: 0.8795 - recall: 0.8557\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1997 - accuracy: 0.8870 - recall: 0.8618\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1944 - accuracy: 0.8849 - recall: 0.8593\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1881 - accuracy: 0.8895 - recall: 0.8699\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1886 - accuracy: 0.8866 - recall: 0.8653\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.1874 - accuracy: 0.8870 - recall: 0.8746\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1797 - accuracy: 0.8955 - recall: 0.8767\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1732 - accuracy: 0.8973 - recall: 0.8763\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1705 - accuracy: 0.9033 - recall: 0.8849\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1655 - accuracy: 0.9005 - recall: 0.8799\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1586 - accuracy: 0.9076 - recall: 0.8923\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1503 - accuracy: 0.9158 - recall: 0.9012\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1478 - accuracy: 0.9183 - recall: 0.9009\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1494 - accuracy: 0.9129 - recall: 0.8991\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1499 - accuracy: 0.9144 - recall: 0.8984\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.1336 - accuracy: 0.9264 - recall: 0.9129\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1418 - accuracy: 0.9225 - recall: 0.9104\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.1464 - accuracy: 0.9176 - recall: 0.9065\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1344 - accuracy: 0.9250 - recall: 0.9055\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.1281 - accuracy: 0.9279 - recall: 0.9129\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1182 - accuracy: 0.9364 - recall: 0.9254\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1275 - accuracy: 0.9261 - recall: 0.9151\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1233 - accuracy: 0.9286 - recall: 0.9193\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1208 - accuracy: 0.9325 - recall: 0.9232\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1159 - accuracy: 0.9350 - recall: 0.9211\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1171 - accuracy: 0.9325 - recall: 0.9232\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1129 - accuracy: 0.9407 - recall: 0.9232\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1112 - accuracy: 0.9378 - recall: 0.9289\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1150 - accuracy: 0.9371 - recall: 0.9257\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1067 - accuracy: 0.9396 - recall: 0.9286\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.1019 - accuracy: 0.9495 - recall: 0.9375\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1062 - accuracy: 0.9410 - recall: 0.9335\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.1061 - accuracy: 0.9410 - recall: 0.9286\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0967 - accuracy: 0.9474 - recall: 0.9414\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0993 - accuracy: 0.9506 - recall: 0.9396\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0933 - accuracy: 0.9524 - recall: 0.9417\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0916 - accuracy: 0.9510 - recall: 0.9428\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0962 - accuracy: 0.9478 - recall: 0.9442\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0999 - accuracy: 0.9499 - recall: 0.9410\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0932 - accuracy: 0.9527 - recall: 0.9463\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0921 - accuracy: 0.9492 - recall: 0.9417\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0829 - accuracy: 0.9609 - recall: 0.9527\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0851 - accuracy: 0.9549 - recall: 0.9488\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0830 - accuracy: 0.9534 - recall: 0.9446\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0925 - accuracy: 0.9534 - recall: 0.9481\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.0805 - accuracy: 0.9588 - recall: 0.9478\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0851 - accuracy: 0.9559 - recall: 0.9510\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0823 - accuracy: 0.9574 - recall: 0.9502\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0879 - accuracy: 0.9527 - recall: 0.9531\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_ohe, epochs=100, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a55630-7267-4377-9314-af00861e3487",
   "metadata": {},
   "source": [
    "## Getting Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c52fd97-f511-4a18-b82c-b13236d64de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Tweet   Stance\n",
      "0     He who exalts himself shall      be humbled; a...  AGAINST\n",
      "1     RT @prayerbullets: I remove Nehushtan -previou...  AGAINST\n",
      "2     @Brainman365 @heidtjj @BenjaminLives I have so...  AGAINST\n",
      "3     #God is utterly powerless without Human interv...  AGAINST\n",
      "4     @David_Cameron   Miracles of #Multiculturalism...  AGAINST\n",
      "...                                                 ...      ...\n",
      "1244  @MetalheadMonty @tom_six I followed him before...     NONE\n",
      "1245  For he who avenges blood remembers, he does no...  AGAINST\n",
      "1246  Life is sacred on all levels. Abortion does no...  AGAINST\n",
      "1247  @ravensymone U refer to \"WE\" which =\"YOU\" & a ...  AGAINST\n",
      "1248  Al Robertson's mom #DuckDynasty  chose life as...  AGAINST\n",
      "\n",
      "[1249 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "with open('testdata-taskA-all-annotations.txt','r', encoding = 'iso-8859-1') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        tweets.append(line.split('\\t'))\n",
    "        \n",
    "mat = np.array(tweets)\n",
    "mat = np.delete(mat, 0, axis=0)\n",
    "\n",
    "df_testing_full = pd.DataFrame(mat, columns = ['ID','Target','Tweet','Stance','Opinion towards', 'Sentiment'])\n",
    "df_testing = df_testing_full.drop(['ID','Opinion towards', 'Target','Sentiment'], axis=1)\n",
    "\n",
    "print(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938d642d-1493-4ea7-9e64-f1925d3641ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGAINST    715\n",
       "FAVOR      304\n",
       "NONE       230\n",
       "Name: Stance, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = df_testing['Stance'].value_counts()\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b198190f-f27d-4ebc-82ec-747120076201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing['Stance'] = le1.transform(df_testing['Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee06c57f-b83f-42ba-baf8-6c4bc92b29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_testing.Tweet)\n",
    "\n",
    "X_test = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_test = df_testing.Stance.astype(np.int32)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed87c30-e3f1-4e62-9807-c09c85f37399",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57fc243a-fd77-41d6-ac0d-acf5ecb72662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 0.9947 - accuracy: 0.5733 - recall: 0.5404\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5d5dd90-b577-4aa3-bba2-febd66212c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c042187-5ee7-4ceb-b776-8ba7386f6405",
   "metadata": {},
   "source": [
    "# One GRU Model For Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c25171-55ab-4dbd-bde2-3773f94e36b6",
   "metadata": {},
   "source": [
    "## Getting Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2909cbbf-2305-4dce-b8a0-cc119dfea29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Tweet   Sentiment\n",
      "0     dear lord thank u for all of ur blessings forg...  POSITIVE\\n\n",
      "1     Blessed are the peacemakers, for they shall be...  POSITIVE\\n\n",
      "2     I am not conformed to this world. I am transfo...  POSITIVE\\n\n",
      "3     Salah should be prayed with #focus and #unders...  POSITIVE\\n\n",
      "4     And stay in your houses and do not display you...  NEGATIVE\\n\n",
      "...                                                 ...         ...\n",
      "2809  There's a law protecting unborn eagles, but no...  NEGATIVE\\n\n",
      "2810  I am 1 in 3... I have had an abortion #Abortio...   NEITHER\\n\n",
      "2811  How dare you say my sexual preference is a cho...  NEGATIVE\\n\n",
      "2812  Equal rights for those 'born that way', no rig...  NEGATIVE\\n\n",
      "2813  #POTUS seals his legacy w/ 1/2 doz wins. The #...  NEGATIVE\\n\n",
      "\n",
      "[2814 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df_full.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fba3649-779b-43a7-95bd-e519fddbfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(df['Sentiment'])\n",
    "df['Sentiment'] = le2.transform(df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1d3181-2577-47ab-95d4-2be975e195a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.Sentiment.astype(np.int32)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f9d09-6d11-42ae-8db7-56bee7ede4a1",
   "metadata": {},
   "source": [
    "## Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f7f79f-a98d-42a6-9c88-4e14901bb8ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 1.0612 - accuracy: 0.5263 - recall: 0.4954\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.5496 - accuracy: 0.6123 - recall: 0.5679\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.4640 - accuracy: 0.6645 - recall: 0.6166\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.4173 - accuracy: 0.7107 - recall: 0.6571\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.4006 - accuracy: 0.7196 - recall: 0.6827\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3740 - accuracy: 0.7534 - recall: 0.7129\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3586 - accuracy: 0.7608 - recall: 0.7164\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3503 - accuracy: 0.7640 - recall: 0.7264\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3428 - accuracy: 0.7729 - recall: 0.7335\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.3283 - accuracy: 0.7804 - recall: 0.7480\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3170 - accuracy: 0.7918 - recall: 0.7601\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3075 - accuracy: 0.7953 - recall: 0.7644\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2887 - accuracy: 0.8067 - recall: 0.7754\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.2807 - accuracy: 0.8188 - recall: 0.7861\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2773 - accuracy: 0.8195 - recall: 0.7910\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2619 - accuracy: 0.8273 - recall: 0.8049\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2498 - accuracy: 0.8468 - recall: 0.8213\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2453 - accuracy: 0.8394 - recall: 0.8138\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2334 - accuracy: 0.8525 - recall: 0.8255\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2331 - accuracy: 0.8536 - recall: 0.8284\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2232 - accuracy: 0.8618 - recall: 0.8429\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.2185 - accuracy: 0.8579 - recall: 0.8408\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2125 - accuracy: 0.8674 - recall: 0.8451\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1973 - accuracy: 0.8721 - recall: 0.8532\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1886 - accuracy: 0.8866 - recall: 0.8667\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1879 - accuracy: 0.8802 - recall: 0.8667\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1874 - accuracy: 0.8859 - recall: 0.8685\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1805 - accuracy: 0.8927 - recall: 0.8703\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1690 - accuracy: 0.8973 - recall: 0.8852\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1692 - accuracy: 0.8937 - recall: 0.8763\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1607 - accuracy: 0.9033 - recall: 0.8859\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.1507 - accuracy: 0.9044 - recall: 0.8952\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1473 - accuracy: 0.9126 - recall: 0.8998\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1463 - accuracy: 0.9158 - recall: 0.9016\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1310 - accuracy: 0.9204 - recall: 0.9094\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.1303 - accuracy: 0.9257 - recall: 0.9112\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1341 - accuracy: 0.9200 - recall: 0.9058\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1238 - accuracy: 0.9289 - recall: 0.9179\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.1189 - accuracy: 0.9339 - recall: 0.9186\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1251 - accuracy: 0.9300 - recall: 0.9161\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1093 - accuracy: 0.9410 - recall: 0.9268\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1106 - accuracy: 0.9382 - recall: 0.9318\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1081 - accuracy: 0.9421 - recall: 0.9282\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1060 - accuracy: 0.9392 - recall: 0.9303\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0994 - accuracy: 0.9467 - recall: 0.9360\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0951 - accuracy: 0.9506 - recall: 0.9410\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0953 - accuracy: 0.9481 - recall: 0.9414\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1075 - accuracy: 0.9410 - recall: 0.9314\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0878 - accuracy: 0.9549 - recall: 0.9467\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0879 - accuracy: 0.9549 - recall: 0.9467\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0872 - accuracy: 0.9527 - recall: 0.9453\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0822 - accuracy: 0.9545 - recall: 0.9481\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0753 - accuracy: 0.9627 - recall: 0.9534\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0778 - accuracy: 0.9549 - recall: 0.9485\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0772 - accuracy: 0.9577 - recall: 0.9513\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0675 - accuracy: 0.9652 - recall: 0.9552\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0770 - accuracy: 0.9556 - recall: 0.9506\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0716 - accuracy: 0.9634 - recall: 0.9620\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0650 - accuracy: 0.9687 - recall: 0.9602\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0735 - accuracy: 0.9598 - recall: 0.9545\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0638 - accuracy: 0.9662 - recall: 0.9616\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0640 - accuracy: 0.9698 - recall: 0.9620\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0574 - accuracy: 0.9687 - recall: 0.9670\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0682 - accuracy: 0.9648 - recall: 0.9591\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0630 - accuracy: 0.9662 - recall: 0.9634\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0525 - accuracy: 0.9773 - recall: 0.9709\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0573 - accuracy: 0.9709 - recall: 0.9666\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0510 - accuracy: 0.9737 - recall: 0.9691\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0542 - accuracy: 0.9716 - recall: 0.9723\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0549 - accuracy: 0.9726 - recall: 0.9655\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0608 - accuracy: 0.9698 - recall: 0.9648\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0498 - accuracy: 0.9741 - recall: 0.9716\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0479 - accuracy: 0.9773 - recall: 0.9723\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0525 - accuracy: 0.9741 - recall: 0.9705\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0495 - accuracy: 0.9762 - recall: 0.9723\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0461 - accuracy: 0.9773 - recall: 0.9723\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0535 - accuracy: 0.9716 - recall: 0.9659\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0513 - accuracy: 0.9762 - recall: 0.9694\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0443 - accuracy: 0.9794 - recall: 0.9755\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0451 - accuracy: 0.9758 - recall: 0.9755\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0463 - accuracy: 0.9751 - recall: 0.9701\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0448 - accuracy: 0.9790 - recall: 0.9744\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0458 - accuracy: 0.9780 - recall: 0.9741\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0404 - accuracy: 0.9822 - recall: 0.9762\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0449 - accuracy: 0.9787 - recall: 0.9741\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0379 - accuracy: 0.9801 - recall: 0.9773\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0447 - accuracy: 0.9776 - recall: 0.9737\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.0358 - accuracy: 0.9822 - recall: 0.9812\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0409 - accuracy: 0.9812 - recall: 0.9751\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0395 - accuracy: 0.9819 - recall: 0.9776\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0337 - accuracy: 0.9844 - recall: 0.9790\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0329 - accuracy: 0.9840 - recall: 0.9801\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0363 - accuracy: 0.9808 - recall: 0.9833\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0389 - accuracy: 0.9812 - recall: 0.9776\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.0411 - accuracy: 0.9790 - recall: 0.9758\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0348 - accuracy: 0.9829 - recall: 0.9780\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0312 - accuracy: 0.9886 - recall: 0.9829\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0339 - accuracy: 0.9829 - recall: 0.9826\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0362 - accuracy: 0.9805 - recall: 0.9790\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0351 - accuracy: 0.9815 - recall: 0.9805\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_ohe, epochs=100, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff42f6-40fa-4a73-a81c-5fb72b003a79",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ef8fa17-e8d3-45a8-8365-eabdb2ffc205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Tweet   Sentiment\n",
      "0     He who exalts himself shall      be humbled; a...  POSITIVE\\n\n",
      "1     RT @prayerbullets: I remove Nehushtan -previou...   NEITHER\\n\n",
      "2     @Brainman365 @heidtjj @BenjaminLives I have so...  POSITIVE\\n\n",
      "3     #God is utterly powerless without Human interv...  NEGATIVE\\n\n",
      "4     @David_Cameron   Miracles of #Multiculturalism...  NEGATIVE\\n\n",
      "...                                                 ...         ...\n",
      "1244  @MetalheadMonty @tom_six I followed him before...  NEGATIVE\\n\n",
      "1245  For he who avenges blood remembers, he does no...   NEITHER\\n\n",
      "1246  Life is sacred on all levels. Abortion does no...   NEITHER\\n\n",
      "1247  @ravensymone U refer to \"WE\" which =\"YOU\" & a ...  NEGATIVE\\n\n",
      "1248  Al Robertson's mom #DuckDynasty  chose life as...   NEITHER\\n\n",
      "\n",
      "[1249 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_testing = df_testing_full.drop(['ID','Opinion towards', 'Target','Stance'], axis=1)\n",
    "\n",
    "print(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2521e919-f117-40f6-ba9e-114c6da9aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing['Sentiment'] = le2.transform(df_testing['Sentiment'])\n",
    "y_test = df_testing.Sentiment.astype(np.int32)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8759b1-22f9-42ad-800c-e02d5b43ebef",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4dbfc11-6851-4150-9bb6-be5085e3f4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 0.8660 - accuracy: 0.7318 - recall: 0.7166\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b91a0fa1-b8ef-4e0d-b1e8-9619b77b3517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step\n",
      "[2 2 2 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ffcec-5af8-4dd9-9edb-f60c24093d98",
   "metadata": {},
   "source": [
    "# Separate Models For Each Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b35b455-2354-4f14-af01-cfb564d4d853",
   "metadata": {},
   "source": [
    "## Hillary Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d01e4b49-4201-4640-8e6f-fe419b1d6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[df_full['Target'] == 'Hillary Clinton']\n",
    "df_stance = df.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_sentiment = df.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0992658c-8106-4d8d-8efb-bd10bb5dbbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df.Tweet)\n",
    "\n",
    "df_stance['Stance'] = le1.transform(df_stance['Stance'])\n",
    "df_sentiment['Sentiment'] = le2.transform(df_sentiment['Sentiment'])\n",
    "X_train = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_train_stance = df_stance.Stance.astype(np.int32)\n",
    "y_train_stance_ohe = keras.utils.to_categorical(y_train_stance, 3)\n",
    "y_train_sentiment = df_sentiment.Sentiment.astype(np.int32)\n",
    "y_train_sentiment_ohe = keras.utils.to_categorical(y_train_sentiment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61467372-b6a9-4dd6-839a-2d9a262bbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df_testing_full[df_testing_full['Target'] == 'Hillary Clinton']\n",
    "df_testing_stance = df_testing.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_testing_sentiment = df_testing.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5339dd62-0c2e-4b80-8084-e02ab01c10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_testing.Tweet)\n",
    "df_testing_stance['Stance'] = le1.transform(df_testing_stance['Stance'])\n",
    "df_testing_sentiment['Sentiment'] = le2.transform(df_testing_sentiment['Sentiment'])\n",
    "\n",
    "X_test = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_test_stance = df_testing_stance.Stance.astype(np.int32)\n",
    "y_test_stance_ohe = keras.utils.to_categorical(y_test_stance, 3)\n",
    "y_test_sentiment = df_testing_sentiment.Sentiment.astype(np.int32)\n",
    "y_test_sentiment_ohe = keras.utils.to_categorical(y_test_sentiment, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c497d-008f-47a0-96bc-56bd82661e70",
   "metadata": {},
   "source": [
    "### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d59b7f05-890c-4096-9dc6-fcb57a133cf9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 1.6146 - accuracy: 0.5258 - recall: 0.5164\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 1.0502 - accuracy: 0.5649 - recall: 0.5415\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.8424 - accuracy: 0.5790 - recall: 0.5336\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6547 - accuracy: 0.6291 - recall: 0.5649\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6000 - accuracy: 0.6557 - recall: 0.5978\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5183 - accuracy: 0.6823 - recall: 0.6385\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5018 - accuracy: 0.6901 - recall: 0.6463\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4541 - accuracy: 0.7027 - recall: 0.6526\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4238 - accuracy: 0.7167 - recall: 0.6808\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3921 - accuracy: 0.7371 - recall: 0.7121\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3755 - accuracy: 0.7277 - recall: 0.6933\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3268 - accuracy: 0.7809 - recall: 0.7465\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3418 - accuracy: 0.7684 - recall: 0.7308\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.2874 - accuracy: 0.8044 - recall: 0.7840\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.2624 - accuracy: 0.8279 - recall: 0.7966\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.2639 - accuracy: 0.8372 - recall: 0.8091\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.2540 - accuracy: 0.8310 - recall: 0.8153\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.2318 - accuracy: 0.8607 - recall: 0.7997\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.2197 - accuracy: 0.8685 - recall: 0.8341\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1985 - accuracy: 0.8685 - recall: 0.8560\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1845 - accuracy: 0.8889 - recall: 0.8685\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1886 - accuracy: 0.8842 - recall: 0.8576\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1674 - accuracy: 0.9061 - recall: 0.8779\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1523 - accuracy: 0.9155 - recall: 0.8920\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1508 - accuracy: 0.9077 - recall: 0.8920\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1310 - accuracy: 0.9155 - recall: 0.8998\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1384 - accuracy: 0.9155 - recall: 0.9045\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1310 - accuracy: 0.9358 - recall: 0.9171\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1401 - accuracy: 0.9218 - recall: 0.9077\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1121 - accuracy: 0.9421 - recall: 0.9327\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1083 - accuracy: 0.9484 - recall: 0.9202\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1083 - accuracy: 0.9421 - recall: 0.9358\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1052 - accuracy: 0.9421 - recall: 0.9343\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1061 - accuracy: 0.9437 - recall: 0.9358\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0835 - accuracy: 0.9562 - recall: 0.9515\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0904 - accuracy: 0.9609 - recall: 0.9468\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0872 - accuracy: 0.9609 - recall: 0.9546\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0808 - accuracy: 0.9656 - recall: 0.9499\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0799 - accuracy: 0.9562 - recall: 0.9515\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0723 - accuracy: 0.9640 - recall: 0.9562\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0636 - accuracy: 0.9765 - recall: 0.9640\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0601 - accuracy: 0.9750 - recall: 0.9593\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0578 - accuracy: 0.9765 - recall: 0.9718\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0633 - accuracy: 0.9624 - recall: 0.9593\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0533 - accuracy: 0.9750 - recall: 0.9750\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0659 - accuracy: 0.9624 - recall: 0.9640\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0542 - accuracy: 0.9750 - recall: 0.9656\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0541 - accuracy: 0.9781 - recall: 0.9734\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0689 - accuracy: 0.9750 - recall: 0.9671\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0401 - accuracy: 0.9875 - recall: 0.9828\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0441 - accuracy: 0.9797 - recall: 0.9797\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0441 - accuracy: 0.9859 - recall: 0.9750\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0496 - accuracy: 0.9718 - recall: 0.9718\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0435 - accuracy: 0.9859 - recall: 0.9765\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0482 - accuracy: 0.9797 - recall: 0.9781\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0455 - accuracy: 0.9797 - recall: 0.9703\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0378 - accuracy: 0.9844 - recall: 0.9844\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0436 - accuracy: 0.9828 - recall: 0.9828\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0252 - accuracy: 0.9937 - recall: 0.9859\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0442 - accuracy: 0.9844 - recall: 0.9781\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0297 - accuracy: 0.9890 - recall: 0.9812\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0321 - accuracy: 0.9844 - recall: 0.9875\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0364 - accuracy: 0.9844 - recall: 0.9781\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0291 - accuracy: 0.9890 - recall: 0.9859\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0248 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0312 - accuracy: 0.9875 - recall: 0.9859\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0319 - accuracy: 0.9859 - recall: 0.9828\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0339 - accuracy: 0.9844 - recall: 0.9859\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0347 - accuracy: 0.9875 - recall: 0.9859\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0249 - accuracy: 0.9844 - recall: 0.9875\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0331 - accuracy: 0.9859 - recall: 0.9781\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0290 - accuracy: 0.9906 - recall: 0.9875\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0200 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0298 - accuracy: 0.9906 - recall: 0.9890\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0333 - accuracy: 0.9844 - recall: 0.9797\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0295 - accuracy: 0.9844 - recall: 0.9859\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0192 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0295 - accuracy: 0.9875 - recall: 0.9859\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0297 - accuracy: 0.9859 - recall: 0.9859\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0243 - accuracy: 0.9906 - recall: 0.9906\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0217 - accuracy: 0.9922 - recall: 0.9906\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0174 - accuracy: 0.9969 - recall: 0.9922\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0259 - accuracy: 0.9906 - recall: 0.9875\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0228 - accuracy: 0.9890 - recall: 0.9890\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0189 - accuracy: 0.9953 - recall: 0.9922\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0142 - accuracy: 0.9922 - recall: 0.9859\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0231 - accuracy: 0.9937 - recall: 0.9859\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0250 - accuracy: 0.9906 - recall: 0.9875\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0242 - accuracy: 0.9906 - recall: 0.9922\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0247 - accuracy: 0.9906 - recall: 0.9875\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0227 - accuracy: 0.9844 - recall: 0.9875\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0178 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0142 - accuracy: 0.9969 - recall: 0.9922\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0142 - accuracy: 0.9953 - recall: 0.9969\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0233 - accuracy: 0.9890 - recall: 0.9875\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0158 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0152 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0203 - accuracy: 0.9890 - recall: 0.9906\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0234 - accuracy: 0.9906 - recall: 0.9906\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0234 - accuracy: 0.9875 - recall: 0.9844\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d896762c-ec0f-4a10-89ec-7fd4c1b7bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3525 - accuracy: 0.5763 - recall: 0.5559\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b122b810-5f2c-4343-ae98-1ea2630cc07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95beda8b-09b0-4955-a4ff-baec068b5cf7",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4979e54e-2539-4c6b-aeb6-4cbdef545882",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0154 - accuracy: 0.9953 - recall: 0.9906\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0209 - accuracy: 0.9906 - recall: 0.9844\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0238 - accuracy: 0.9922 - recall: 0.9828\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0211 - accuracy: 0.9906 - recall: 0.9875\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0126 - accuracy: 0.9922 - recall: 0.9937\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0073 - accuracy: 0.9984 - recall: 0.9984\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0115 - accuracy: 0.9969 - recall: 0.9937\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0151 - accuracy: 0.9937 - recall: 0.9937\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0216 - accuracy: 0.9875 - recall: 0.9875\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0167 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0192 - accuracy: 0.9922 - recall: 0.9906\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0127 - accuracy: 0.9937 - recall: 0.9906\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.0215 - accuracy: 0.9937 - recall: 0.9937\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0173 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0128 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0178 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0174 - accuracy: 0.9906 - recall: 0.9906\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0071 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0103 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0097 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0152 - accuracy: 0.9953 - recall: 0.9922\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0120 - accuracy: 0.9984 - recall: 0.9984\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0111 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0152 - accuracy: 0.9906 - recall: 0.9906\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0145 - accuracy: 0.9937 - recall: 0.9953\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0083 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0134 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0242 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0156 - accuracy: 0.9937 - recall: 0.9937\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0139 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0090 - accuracy: 0.9969 - recall: 0.9937\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0123 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0127 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0097 - accuracy: 0.9937 - recall: 0.9953\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0092 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0199 - accuracy: 0.9906 - recall: 0.9937\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0072 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0198 - accuracy: 0.9875 - recall: 0.9890\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0077 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0081 - accuracy: 0.9984 - recall: 0.9984\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0056 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0120 - accuracy: 0.9969 - recall: 0.9937\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0070 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0090 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0161 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0102 - accuracy: 0.9984 - recall: 0.9984\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0036 - accuracy: 1.0000 - recall: 0.9984\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0079 - accuracy: 0.9953 - recall: 0.9969\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0115 - accuracy: 0.9937 - recall: 0.9953\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0057 - accuracy: 0.9984 - recall: 0.9969\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0159 - accuracy: 0.9922 - recall: 0.9906\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0106 - accuracy: 0.9937 - recall: 0.9937\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0114 - accuracy: 0.9922 - recall: 0.9953\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0130 - accuracy: 0.9906 - recall: 0.9937\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0086 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0100 - accuracy: 0.9953 - recall: 0.9937\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0083 - accuracy: 0.9953 - recall: 0.9969\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0187 - accuracy: 0.9859 - recall: 0.9859\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0121 - accuracy: 0.9937 - recall: 0.9937\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0068 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0170 - accuracy: 0.9906 - recall: 0.9890\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0096 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0132 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0084 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0088 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0185 - accuracy: 0.9937 - recall: 0.9906\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0103 - accuracy: 0.9953 - recall: 0.9969\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0093 - accuracy: 0.9953 - recall: 0.9922\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0055 - accuracy: 0.9984 - recall: 0.9969\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0062 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0085 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0068 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0085 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0086 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0079 - accuracy: 0.9984 - recall: 0.9984\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0102 - accuracy: 0.9937 - recall: 0.9922\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0056 - accuracy: 0.9969 - recall: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0045 - accuracy: 1.0000 - recall: 0.9984\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0067 - accuracy: 0.9953 - recall: 0.9969\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0111 - accuracy: 0.9922 - recall: 0.9969\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0077 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0149 - accuracy: 0.9937 - recall: 0.9953\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0133 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0078 - accuracy: 0.9953 - recall: 0.9937\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0074 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0097 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0102 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0069 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0090 - accuracy: 0.9953 - recall: 0.9937\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0072 - accuracy: 0.9969 - recall: 0.9953\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0092 - accuracy: 0.9953 - recall: 0.9953\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0064 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0048 - accuracy: 0.9984 - recall: 0.9984\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0103 - accuracy: 0.9953 - recall: 0.9922\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0047 - accuracy: 0.9969 - recall: 0.9969\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0050 - accuracy: 0.9984 - recall: 0.9984\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0063 - accuracy: 0.9953 - recall: 0.9969\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0054 - accuracy: 0.9953 - recall: 0.9984\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0042 - accuracy: 1.0000 - recall: 0.9984\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0101 - accuracy: 0.9953 - recall: 0.9953\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca8e4443-22b9-4883-a85d-aac530dabf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5479 - accuracy: 0.5559 - recall: 0.5322\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb4dd74c-bf31-4891-97ee-199862db1a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a70417-7674-4982-a22b-5d9efa61603a",
   "metadata": {},
   "source": [
    "## Climate Change is a Real Concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f8d20af-4c67-4a78-9be5-898f203672de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[df_full['Target'] == 'Climate Change is a Real Concern']\n",
    "df_stance = df.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_sentiment = df.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2e9e350-1edb-43e8-b2c9-d09ce39e6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df.Tweet)\n",
    "\n",
    "df_stance['Stance'] = le1.transform(df_stance['Stance'])\n",
    "df_sentiment['Sentiment'] = le2.transform(df_sentiment['Sentiment'])\n",
    "X_train = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_train_stance = df_stance.Stance.astype(np.int32)\n",
    "y_train_stance_ohe = keras.utils.to_categorical(y_train_stance, 3)\n",
    "y_train_sentiment = df_sentiment.Sentiment.astype(np.int32)\n",
    "y_train_sentiment_ohe = keras.utils.to_categorical(y_train_sentiment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f5bce0a-1b07-46fa-b85f-f7260ade9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df_testing_full[df_testing_full['Target'] == 'Climate Change is a Real Concern']\n",
    "df_testing_stance = df_testing.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_testing_sentiment = df_testing.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91c5779a-f972-4924-8bfe-c2be4b2f090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_testing.Tweet)\n",
    "df_testing_stance['Stance'] = le1.transform(df_testing_stance['Stance'])\n",
    "df_testing_sentiment['Sentiment'] = le2.transform(df_testing_sentiment['Sentiment'])\n",
    "\n",
    "X_test = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_test_stance = df_testing_stance.Stance.astype(np.int32)\n",
    "y_test_stance_ohe = keras.utils.to_categorical(y_test_stance, 3)\n",
    "y_test_sentiment = df_testing_sentiment.Sentiment.astype(np.int32)\n",
    "y_test_sentiment_ohe = keras.utils.to_categorical(y_test_sentiment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d79d1670-ca32-4d4b-be78-dd5539fceea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_full[df_full['Target'] == 'Climate Change is a Real Concern']\n",
    "df_stance = df.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_sentiment = df.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92152f41-abe7-44a5-869f-6a398a6009e5",
   "metadata": {},
   "source": [
    "### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9509c64f-dcdd-4ee6-a005-068e47c040e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 1.5155 - accuracy: 0.5342 - recall: 0.5063\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.8044 - accuracy: 0.6506 - recall: 0.6633\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.6496 - accuracy: 0.6962 - recall: 0.6861\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4331 - accuracy: 0.7646 - recall: 0.7722\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.4503 - accuracy: 0.7975 - recall: 0.7772\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.4352 - accuracy: 0.8000 - recall: 0.8000\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3600 - accuracy: 0.8076 - recall: 0.7899\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2918 - accuracy: 0.8228 - recall: 0.8051\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3131 - accuracy: 0.8354 - recall: 0.8354\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2915 - accuracy: 0.8582 - recall: 0.8405\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2418 - accuracy: 0.8684 - recall: 0.8430\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.2431 - accuracy: 0.8734 - recall: 0.8684\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2025 - accuracy: 0.8785 - recall: 0.8709\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.1839 - accuracy: 0.9013 - recall: 0.8987\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.1805 - accuracy: 0.8911 - recall: 0.8734\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1757 - accuracy: 0.9038 - recall: 0.8911\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1590 - accuracy: 0.9215 - recall: 0.9291\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0878 - accuracy: 0.9570 - recall: 0.9570\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1116 - accuracy: 0.9367 - recall: 0.9367\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1380 - accuracy: 0.9266 - recall: 0.9114\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1053 - accuracy: 0.9494 - recall: 0.9392\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0807 - accuracy: 0.9671 - recall: 0.9443\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1036 - accuracy: 0.9494 - recall: 0.9367\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0749 - accuracy: 0.9646 - recall: 0.9544\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0911 - accuracy: 0.9544 - recall: 0.9494\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.1120 - accuracy: 0.9342 - recall: 0.9392\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0705 - accuracy: 0.9722 - recall: 0.9646\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0638 - accuracy: 0.9696 - recall: 0.9570\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0876 - accuracy: 0.9468 - recall: 0.9443\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0470 - accuracy: 0.9722 - recall: 0.9722\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0757 - accuracy: 0.9646 - recall: 0.9544\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0627 - accuracy: 0.9671 - recall: 0.9646\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0502 - accuracy: 0.9696 - recall: 0.9646\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0503 - accuracy: 0.9747 - recall: 0.9671\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0347 - accuracy: 0.9823 - recall: 0.9873\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0462 - accuracy: 0.9797 - recall: 0.9772\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0251 - accuracy: 0.9924 - recall: 0.9899\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0419 - accuracy: 0.9747 - recall: 0.9747\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0336 - accuracy: 0.9823 - recall: 0.9747\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0271 - accuracy: 0.9873 - recall: 0.9899\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0374 - accuracy: 0.9823 - recall: 0.9848\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0228 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0245 - accuracy: 0.9899 - recall: 0.9873\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0302 - accuracy: 0.9848 - recall: 0.9823\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0397 - accuracy: 0.9747 - recall: 0.9747\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0266 - accuracy: 0.9848 - recall: 0.9797\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0233 - accuracy: 0.9899 - recall: 0.9848\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0358 - accuracy: 0.9797 - recall: 0.9797\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0152 - accuracy: 0.9924 - recall: 0.9899\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0214 - accuracy: 0.9924 - recall: 0.9899\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0363 - accuracy: 0.9797 - recall: 0.9797\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0176 - accuracy: 0.9949 - recall: 0.9924\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0093 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0313 - accuracy: 0.9848 - recall: 0.9823\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0274 - accuracy: 0.9873 - recall: 0.9899\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 0.9899 - recall: 0.9949\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0089 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0161 - accuracy: 0.9899 - recall: 0.9924\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0141 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0216 - accuracy: 0.9924 - recall: 0.9924\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0166 - accuracy: 0.9924 - recall: 0.9924\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0227 - accuracy: 0.9899 - recall: 0.9873\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0240 - accuracy: 0.9873 - recall: 0.9823\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0129 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0075 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0134 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0080 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0241 - accuracy: 0.9899 - recall: 0.9848\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0173 - accuracy: 0.9924 - recall: 0.9899\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0080 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0098 - accuracy: 0.9975 - recall: 0.9949\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0253 - accuracy: 0.9899 - recall: 0.9848\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0068 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0203 - accuracy: 0.9899 - recall: 0.9899\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0202 - accuracy: 0.9924 - recall: 0.9924\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0079 - accuracy: 0.9975 - recall: 1.0000\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0118 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0045 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0162 - accuracy: 0.9924 - recall: 0.9949\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0094 - accuracy: 0.9949 - recall: 0.9975\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0045 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0040 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0175 - accuracy: 0.9899 - recall: 0.9924\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0041 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0034 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0067 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0087 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0197 - accuracy: 0.9924 - recall: 0.9924\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0103 - accuracy: 0.9924 - recall: 0.9924\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0170 - accuracy: 0.9949 - recall: 0.9975\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0049 - accuracy: 0.9975 - recall: 1.0000\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0080 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0032 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0078 - accuracy: 0.9975 - recall: 0.9949\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0037 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0057 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0095 - accuracy: 0.9899 - recall: 0.9899\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0045 - accuracy: 0.9975 - recall: 0.9975\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4d3eecd-e98b-4fed-ae3a-55f8b401dd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0892 - accuracy: 0.7811 - recall: 0.7633\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "060c62b5-8a47-4cfd-a521-23edc05ba878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d59dc7-557a-42f8-b75a-eb9a984be34f",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1657b072-3c32-4647-b234-d30be39e6162",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0080 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0085 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0122 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0038 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0049 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0013 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0094 - accuracy: 0.9924 - recall: 0.9949\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0021 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0027 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0062 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0056 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0093 - accuracy: 0.9975 - recall: 0.9949\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0024 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 8.0919e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 7.6722e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 9.7592e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 9.1165e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0039 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0149 - accuracy: 0.9899 - recall: 0.9899\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0010 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 9.3174e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 7.8325e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0046 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0142 - accuracy: 0.9899 - recall: 0.9924\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0010 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0051 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0041 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 6.2674e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0045 - accuracy: 0.9975 - recall: 0.9949\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 6.0597e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0149 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 6.6507e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 0.9975 - recall: 1.0000\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 9.5895e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 4.6257e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0062 - accuracy: 0.9949 - recall: 1.0000\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0053 - accuracy: 0.9949 - recall: 0.9975\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 3.3404e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0048 - accuracy: 0.9975 - recall: 0.9949\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0021 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 7.0335e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 6.9242e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0037 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 8.1750e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0095 - accuracy: 0.9949 - recall: 0.9924\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0027 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 2.5298e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 5.2399e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 1.6641e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0093 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 7.5592e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 6.3220e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 2.4347e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0086 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000 - recall: 0.9975\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0056 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 1.0137e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 3.6602e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0058 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 4.1061e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 8.5932e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 6.5675e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 4.6357e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0090 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 1.1068e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 5.7518e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 6.1383e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 0.9975 - recall: 0.9975\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 8.9176e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 7.9300e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 5.6957e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0053 - accuracy: 0.9949 - recall: 0.9975\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0164 - accuracy: 0.9949 - recall: 0.9924\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 1.9386e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 4.0879e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0081 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 1.9184e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0049 - accuracy: 0.9949 - recall: 0.9949\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0121 - accuracy: 0.9899 - recall: 0.9924\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0010 - accuracy: 1.0000 - recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c4beb7d-b59d-4d03-94b1-5401158b040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3986 - accuracy: 0.7515 - recall: 0.7396\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "237ed954-55b5-4129-bbc0-05ebc46af238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cab277-7076-4172-a130-ebc42f84cba3",
   "metadata": {},
   "source": [
    "## Feminist Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b7b6a4e-5c80-42c5-af52-913cc9aadd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[df_full['Target'] == 'Feminist Movement']\n",
    "df_stance = df.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_sentiment = df.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b58725b-d479-4d26-84c1-5d1ab8bbbfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df.Tweet)\n",
    "\n",
    "df_stance['Stance'] = le1.transform(df_stance['Stance'])\n",
    "df_sentiment['Sentiment'] = le2.transform(df_sentiment['Sentiment'])\n",
    "X_train = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_train_stance = df_stance.Stance.astype(np.int32)\n",
    "y_train_stance_ohe = keras.utils.to_categorical(y_train_stance, 3)\n",
    "y_train_sentiment = df_sentiment.Sentiment.astype(np.int32)\n",
    "y_train_sentiment_ohe = keras.utils.to_categorical(y_train_sentiment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71d814b7-1a34-4cbc-8ca0-fd6e50dccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df_testing_full[df_testing_full['Target'] == 'Hillary Clinton']\n",
    "df_testing_stance = df_testing.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_testing_sentiment = df_testing.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "abd8bd52-d679-494a-bee4-7dfad12c311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_testing.Tweet)\n",
    "df_testing_stance['Stance'] = le1.transform(df_testing_stance['Stance'])\n",
    "df_testing_sentiment['Sentiment'] = le2.transform(df_testing_sentiment['Sentiment'])\n",
    "\n",
    "X_test = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_test_stance = df_testing_stance.Stance.astype(np.int32)\n",
    "y_test_stance_ohe = keras.utils.to_categorical(y_test_stance, 3)\n",
    "y_test_sentiment = df_testing_sentiment.Sentiment.astype(np.int32)\n",
    "y_test_sentiment_ohe = keras.utils.to_categorical(y_test_sentiment, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddd77b-05c9-492e-8053-e6df04cd4052",
   "metadata": {},
   "source": [
    "### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0349d9aa-1621-414c-b0fd-8ae13ca11c28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 1.3563 - accuracy: 0.5723 - recall: 0.5497\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.8423 - accuracy: 0.6627 - recall: 0.6325\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.7046 - accuracy: 0.6747 - recall: 0.6506\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.6038 - accuracy: 0.6988 - recall: 0.6566\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5329 - accuracy: 0.7485 - recall: 0.7063\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5221 - accuracy: 0.7410 - recall: 0.6973\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4131 - accuracy: 0.7681 - recall: 0.7214\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3923 - accuracy: 0.7801 - recall: 0.7440\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3349 - accuracy: 0.7952 - recall: 0.7636\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3630 - accuracy: 0.7907 - recall: 0.7605\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3252 - accuracy: 0.8042 - recall: 0.7771\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2661 - accuracy: 0.8479 - recall: 0.8117\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2735 - accuracy: 0.8343 - recall: 0.8117\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2575 - accuracy: 0.8389 - recall: 0.8072\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2320 - accuracy: 0.8765 - recall: 0.8464\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2093 - accuracy: 0.8690 - recall: 0.8539\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2101 - accuracy: 0.8765 - recall: 0.8554\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1855 - accuracy: 0.8825 - recall: 0.8675\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1651 - accuracy: 0.8931 - recall: 0.8810\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1655 - accuracy: 0.9127 - recall: 0.8976\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1732 - accuracy: 0.8931 - recall: 0.8765\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1401 - accuracy: 0.9202 - recall: 0.9051\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1453 - accuracy: 0.9202 - recall: 0.8976\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1357 - accuracy: 0.9187 - recall: 0.9111\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1193 - accuracy: 0.9322 - recall: 0.9187\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1076 - accuracy: 0.9503 - recall: 0.9398\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1354 - accuracy: 0.9337 - recall: 0.9202\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1106 - accuracy: 0.9398 - recall: 0.9398\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0940 - accuracy: 0.9443 - recall: 0.9307\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1098 - accuracy: 0.9307 - recall: 0.9262\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1024 - accuracy: 0.9458 - recall: 0.9247\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0897 - accuracy: 0.9518 - recall: 0.9443\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0773 - accuracy: 0.9654 - recall: 0.9533\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0814 - accuracy: 0.9548 - recall: 0.9518\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0868 - accuracy: 0.9578 - recall: 0.9518\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0693 - accuracy: 0.9654 - recall: 0.9714\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0801 - accuracy: 0.9593 - recall: 0.9488\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0631 - accuracy: 0.9669 - recall: 0.9639\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0509 - accuracy: 0.9669 - recall: 0.9699\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0495 - accuracy: 0.9804 - recall: 0.9684\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0409 - accuracy: 0.9789 - recall: 0.9819\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0571 - accuracy: 0.9729 - recall: 0.9714\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0575 - accuracy: 0.9699 - recall: 0.9714\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0633 - accuracy: 0.9669 - recall: 0.9684\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0598 - accuracy: 0.9714 - recall: 0.9699\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0554 - accuracy: 0.9744 - recall: 0.9714\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0516 - accuracy: 0.9774 - recall: 0.9699\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0444 - accuracy: 0.9774 - recall: 0.9729\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0500 - accuracy: 0.9744 - recall: 0.9684\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0297 - accuracy: 0.9880 - recall: 0.9819\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0325 - accuracy: 0.9864 - recall: 0.9834\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0402 - accuracy: 0.9804 - recall: 0.9729\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0500 - accuracy: 0.9774 - recall: 0.9774\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0366 - accuracy: 0.9864 - recall: 0.9834\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0576 - accuracy: 0.9759 - recall: 0.9714\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0253 - accuracy: 0.9910 - recall: 0.9849\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0276 - accuracy: 0.9864 - recall: 0.9880\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0430 - accuracy: 0.9789 - recall: 0.9819\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0313 - accuracy: 0.9849 - recall: 0.9774\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0321 - accuracy: 0.9910 - recall: 0.9880\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0378 - accuracy: 0.9864 - recall: 0.9834\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0300 - accuracy: 0.9864 - recall: 0.9864\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0204 - accuracy: 0.9910 - recall: 0.9834\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0252 - accuracy: 0.9910 - recall: 0.9849\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0264 - accuracy: 0.9880 - recall: 0.9849\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0241 - accuracy: 0.9849 - recall: 0.9849\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0243 - accuracy: 0.9910 - recall: 0.9895\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0239 - accuracy: 0.9910 - recall: 0.9895\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0236 - accuracy: 0.9895 - recall: 0.9834\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0325 - accuracy: 0.9864 - recall: 0.9834\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0242 - accuracy: 0.9880 - recall: 0.9864\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0252 - accuracy: 0.9895 - recall: 0.9834\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0228 - accuracy: 0.9895 - recall: 0.9880\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0196 - accuracy: 0.9925 - recall: 0.9925\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0184 - accuracy: 0.9910 - recall: 0.9895\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0198 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0275 - accuracy: 0.9849 - recall: 0.9834\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0331 - accuracy: 0.9834 - recall: 0.9804\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0266 - accuracy: 0.9895 - recall: 0.9895\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0198 - accuracy: 0.9925 - recall: 0.9910\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0306 - accuracy: 0.9880 - recall: 0.9895\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0230 - accuracy: 0.9834 - recall: 0.9834\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0298 - accuracy: 0.9864 - recall: 0.9834\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0220 - accuracy: 0.9895 - recall: 0.9910\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0194 - accuracy: 0.9940 - recall: 0.9910\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0315 - accuracy: 0.9849 - recall: 0.9849\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0176 - accuracy: 0.9955 - recall: 0.9895\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0177 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0154 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0278 - accuracy: 0.9895 - recall: 0.9895\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0234 - accuracy: 0.9940 - recall: 0.9910\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0123 - accuracy: 0.9970 - recall: 0.9955\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0215 - accuracy: 0.9895 - recall: 0.9895\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0102 - accuracy: 0.9940 - recall: 0.9940\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0118 - accuracy: 0.9955 - recall: 0.9940\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0160 - accuracy: 0.9955 - recall: 0.9925\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0145 - accuracy: 0.9925 - recall: 0.9940\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0109 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0157 - accuracy: 0.9925 - recall: 0.9955\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0242 - accuracy: 0.9925 - recall: 0.9940\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c569f0b-0e87-46c6-8c49-2a2636b8c04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4981 - accuracy: 0.5322 - recall: 0.5051\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30c8f310-2fb4-419e-904f-9cbd1ba10cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96659ee7-54e1-4056-896e-a5db59a1a50a",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3815d5dc-f38b-4952-96c6-82095ffe3374",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0183 - accuracy: 0.9895 - recall: 0.9925\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0242 - accuracy: 0.9849 - recall: 0.9849\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0195 - accuracy: 0.9895 - recall: 0.9925\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0150 - accuracy: 0.9925 - recall: 0.9910\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0153 - accuracy: 0.9925 - recall: 0.9925\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0179 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0100 - accuracy: 0.9970 - recall: 0.9955\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0157 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0123 - accuracy: 0.9940 - recall: 0.9955\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0112 - accuracy: 0.9955 - recall: 0.9955\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0206 - accuracy: 0.9910 - recall: 0.9864\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0113 - accuracy: 0.9970 - recall: 0.9940\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0054 - accuracy: 0.9985 - recall: 1.0000\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0083 - accuracy: 0.9955 - recall: 0.9955\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0093 - accuracy: 0.9970 - recall: 0.9955\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0145 - accuracy: 0.9955 - recall: 0.9925\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0085 - accuracy: 0.9955 - recall: 0.9955\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0168 - accuracy: 0.9940 - recall: 0.9910\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0201 - accuracy: 0.9925 - recall: 0.9880\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0083 - accuracy: 0.9985 - recall: 0.9940\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0043 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0109 - accuracy: 0.9940 - recall: 0.9955\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0114 - accuracy: 0.9955 - recall: 0.9940\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0157 - accuracy: 0.9940 - recall: 0.9940\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0063 - accuracy: 0.9970 - recall: 0.9985\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0043 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0094 - accuracy: 0.9955 - recall: 0.9940\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0117 - accuracy: 0.9970 - recall: 0.9955\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0093 - accuracy: 0.9955 - recall: 0.9940\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0108 - accuracy: 0.9955 - recall: 0.9955\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0060 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0153 - accuracy: 0.9925 - recall: 0.9940\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0170 - accuracy: 0.9895 - recall: 0.9895\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0117 - accuracy: 0.9940 - recall: 0.9970\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0196 - accuracy: 0.9940 - recall: 0.9940\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0079 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0188 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0112 - accuracy: 0.9955 - recall: 0.9910\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0134 - accuracy: 0.9940 - recall: 0.9940\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0118 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0060 - accuracy: 1.0000 - recall: 0.9940\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0057 - accuracy: 0.9985 - recall: 0.9970\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0078 - accuracy: 0.9955 - recall: 0.9925\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0175 - accuracy: 0.9955 - recall: 0.9955\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0060 - accuracy: 0.9985 - recall: 0.9970\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.0087 - accuracy: 0.9955 - recall: 0.9955\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0110 - accuracy: 0.9940 - recall: 0.9925\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0092 - accuracy: 0.9970 - recall: 0.9985\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0053 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0099 - accuracy: 0.9955 - recall: 0.9955\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0102 - accuracy: 0.9970 - recall: 0.9955\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0098 - accuracy: 0.9970 - recall: 0.9970\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0045 - accuracy: 0.9985 - recall: 0.9970\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0079 - accuracy: 0.9970 - recall: 0.9970\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0085 - accuracy: 0.9985 - recall: 0.9955\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0047 - accuracy: 0.9985 - recall: 0.9970\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0097 - accuracy: 0.9940 - recall: 0.9940\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0075 - accuracy: 0.9970 - recall: 0.9955\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0063 - accuracy: 0.9985 - recall: 0.9955\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0088 - accuracy: 0.9955 - recall: 0.9970\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0039 - accuracy: 0.9985 - recall: 0.9940\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0082 - accuracy: 0.9940 - recall: 0.9955\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.0063 - accuracy: 0.9970 - recall: 0.9970\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0056 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0031 - accuracy: 1.0000 - recall: 0.9985\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0059 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0053 - accuracy: 1.0000 - recall: 0.9970\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0032 - accuracy: 0.9985 - recall: 1.0000\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0039 - accuracy: 0.9970 - recall: 0.9985\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0055 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0049 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0060 - accuracy: 0.9970 - recall: 0.9970\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0035 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0078 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0058 - accuracy: 0.9985 - recall: 0.9955\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.0021 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0055 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0028 - accuracy: 1.0000 - recall: 0.9985\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0117 - accuracy: 0.9925 - recall: 0.9910\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0071 - accuracy: 0.9955 - recall: 0.9970\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0027 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0018 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0073 - accuracy: 0.9955 - recall: 0.9970\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0063 - accuracy: 0.9985 - recall: 0.9955\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0052 - accuracy: 0.9970 - recall: 0.9955\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0031 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0083 - accuracy: 0.9970 - recall: 0.9970\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0045 - accuracy: 0.9985 - recall: 0.9970\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0055 - accuracy: 0.9970 - recall: 0.9970\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0071 - accuracy: 0.9970 - recall: 0.9940\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.0074 - accuracy: 0.9955 - recall: 0.9970\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0031 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0208 - accuracy: 0.9955 - recall: 0.9940\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0047 - accuracy: 0.9970 - recall: 0.9970\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0052 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0032 - accuracy: 1.0000 - recall: 0.9985\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0028 - accuracy: 0.9985 - recall: 0.9985\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0088 - accuracy: 0.9985 - recall: 0.9970\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a588950b-115c-4cf9-8997-9f22369b0723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7708 - accuracy: 0.5186 - recall: 0.5119\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94467d7a-96fb-43fd-b872-260f16fa9e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c4d5f-5bb9-4386-a36e-649620e63dcc",
   "metadata": {},
   "source": [
    "## Legalization of Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7c922b0-30e9-4b13-b71c-469a687c11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[df_full['Target'] == 'Legalization of Abortion']\n",
    "df_stance = df.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_sentiment = df.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17198ecc-5135-4a27-bd56-6c79f65e56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df.Tweet)\n",
    "\n",
    "df_stance['Stance'] = le1.transform(df_stance['Stance'])\n",
    "df_sentiment['Sentiment'] = le2.transform(df_sentiment['Sentiment'])\n",
    "X_train = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_train_stance = df_stance.Stance.astype(np.int32)\n",
    "y_train_stance_ohe = keras.utils.to_categorical(y_train_stance, 3)\n",
    "y_train_sentiment = df_sentiment.Sentiment.astype(np.int32)\n",
    "y_train_sentiment_ohe = keras.utils.to_categorical(y_train_sentiment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9ae7e4c-fd89-4ccd-a3c7-4722d8056fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df_testing_full[df_testing_full['Target'] == 'Legalization of Abortion']\n",
    "df_testing_stance = df_testing.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_testing_sentiment = df_testing.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5f03c78-2411-4cdc-a67f-426229ac58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_testing.Tweet)\n",
    "df_testing_stance['Stance'] = le1.transform(df_testing_stance['Stance'])\n",
    "df_testing_sentiment['Sentiment'] = le2.transform(df_testing_sentiment['Sentiment'])\n",
    "\n",
    "X_test = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_test_stance = df_testing_stance.Stance.astype(np.int32)\n",
    "y_test_stance_ohe = keras.utils.to_categorical(y_test_stance, 3)\n",
    "y_test_sentiment = df_testing_sentiment.Sentiment.astype(np.int32)\n",
    "y_test_sentiment_ohe = keras.utils.to_categorical(y_test_sentiment, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f421f2-4b55-4346-88c6-320d0e75506b",
   "metadata": {},
   "source": [
    "### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e017205-c7f6-4915-b6c5-2d2e6408dfc4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 1.1382 - accuracy: 0.6335 - recall: 0.6070\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.7486 - accuracy: 0.7015 - recall: 0.6733\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.6760 - accuracy: 0.7114 - recall: 0.6667\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.5834 - accuracy: 0.7081 - recall: 0.6965\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.4768 - accuracy: 0.7512 - recall: 0.7048\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.4617 - accuracy: 0.7761 - recall: 0.7413\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.4269 - accuracy: 0.7711 - recall: 0.7446\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3580 - accuracy: 0.8027 - recall: 0.7612\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.3246 - accuracy: 0.8226 - recall: 0.7811\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.2915 - accuracy: 0.8408 - recall: 0.8060\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.2614 - accuracy: 0.8491 - recall: 0.8391\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.2541 - accuracy: 0.8441 - recall: 0.8275\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.1966 - accuracy: 0.8922 - recall: 0.8640\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1904 - accuracy: 0.8922 - recall: 0.8773\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.2063 - accuracy: 0.8773 - recall: 0.8590\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1670 - accuracy: 0.8922 - recall: 0.8723\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1686 - accuracy: 0.9088 - recall: 0.9022\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1726 - accuracy: 0.9005 - recall: 0.8789\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1433 - accuracy: 0.9187 - recall: 0.9138\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1476 - accuracy: 0.9221 - recall: 0.8856\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1425 - accuracy: 0.9154 - recall: 0.9022\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1105 - accuracy: 0.9403 - recall: 0.9303\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1369 - accuracy: 0.9237 - recall: 0.9187\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0914 - accuracy: 0.9453 - recall: 0.9469\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1224 - accuracy: 0.9337 - recall: 0.9154\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0875 - accuracy: 0.9502 - recall: 0.9469\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0873 - accuracy: 0.9453 - recall: 0.9370\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0890 - accuracy: 0.9635 - recall: 0.9502\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0880 - accuracy: 0.9453 - recall: 0.9420\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0953 - accuracy: 0.9502 - recall: 0.9502\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0741 - accuracy: 0.9652 - recall: 0.9585\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0674 - accuracy: 0.9701 - recall: 0.9668\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0675 - accuracy: 0.9685 - recall: 0.9619\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0713 - accuracy: 0.9668 - recall: 0.9585\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0537 - accuracy: 0.9701 - recall: 0.9635\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0566 - accuracy: 0.9668 - recall: 0.9602\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0423 - accuracy: 0.9801 - recall: 0.9784\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0555 - accuracy: 0.9768 - recall: 0.9668\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0543 - accuracy: 0.9735 - recall: 0.9701\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0409 - accuracy: 0.9784 - recall: 0.9652\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0514 - accuracy: 0.9801 - recall: 0.9768\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0387 - accuracy: 0.9851 - recall: 0.9818\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0430 - accuracy: 0.9834 - recall: 0.9784\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0402 - accuracy: 0.9818 - recall: 0.9768\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0375 - accuracy: 0.9801 - recall: 0.9801\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0290 - accuracy: 0.9851 - recall: 0.9884\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0321 - accuracy: 0.9884 - recall: 0.9834\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0533 - accuracy: 0.9834 - recall: 0.9768\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0404 - accuracy: 0.9834 - recall: 0.9784\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0193 - accuracy: 0.9934 - recall: 0.9884\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0465 - accuracy: 0.9784 - recall: 0.9768\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0231 - accuracy: 0.9900 - recall: 0.9867\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0337 - accuracy: 0.9801 - recall: 0.9735\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0273 - accuracy: 0.9867 - recall: 0.9834\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0262 - accuracy: 0.9867 - recall: 0.9917\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0214 - accuracy: 0.9934 - recall: 0.9884\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0213 - accuracy: 0.9934 - recall: 0.9900\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0385 - accuracy: 0.9818 - recall: 0.9801\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0221 - accuracy: 0.9884 - recall: 0.9884\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0262 - accuracy: 0.9867 - recall: 0.9884\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0344 - accuracy: 0.9834 - recall: 0.9834\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0184 - accuracy: 0.9900 - recall: 0.9851\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0191 - accuracy: 0.9950 - recall: 0.9917\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0149 - accuracy: 0.9934 - recall: 0.9950\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0174 - accuracy: 0.9900 - recall: 0.9884\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0162 - accuracy: 0.9900 - recall: 0.9917\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0194 - accuracy: 0.9917 - recall: 0.9900\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0226 - accuracy: 0.9884 - recall: 0.9917\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0195 - accuracy: 0.9934 - recall: 0.9967\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0179 - accuracy: 0.9900 - recall: 0.9900\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0202 - accuracy: 0.9917 - recall: 0.9917\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0138 - accuracy: 0.9967 - recall: 0.9950\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0202 - accuracy: 0.9900 - recall: 0.9900\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0135 - accuracy: 0.9917 - recall: 0.9917\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0212 - accuracy: 0.9884 - recall: 0.9950\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0221 - accuracy: 0.9900 - recall: 0.9884\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0276 - accuracy: 0.9900 - recall: 0.9867\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0229 - accuracy: 0.9900 - recall: 0.9900\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0117 - accuracy: 0.9934 - recall: 0.9967\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0214 - accuracy: 0.9851 - recall: 0.9834\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0171 - accuracy: 0.9900 - recall: 0.9884\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0148 - accuracy: 0.9917 - recall: 0.9917\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0163 - accuracy: 0.9884 - recall: 0.9917\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 0.9950 - recall: 0.9917\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0165 - accuracy: 0.9884 - recall: 0.9884\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0235 - accuracy: 0.9900 - recall: 0.9884\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0149 - accuracy: 0.9950 - recall: 0.9884\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0216 - accuracy: 0.9950 - recall: 0.9917\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0135 - accuracy: 0.9934 - recall: 0.9917\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0191 - accuracy: 0.9900 - recall: 0.9900\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0155 - accuracy: 0.9934 - recall: 0.9884\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0177 - accuracy: 0.9884 - recall: 0.9900\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0147 - accuracy: 0.9950 - recall: 0.9917\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0156 - accuracy: 0.9934 - recall: 0.9934\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0177 - accuracy: 0.9917 - recall: 0.9900\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0188 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0226 - accuracy: 0.9900 - recall: 0.9900\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0114 - accuracy: 0.9983 - recall: 0.9917\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0162 - accuracy: 0.9917 - recall: 0.9917\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0153 - accuracy: 0.9917 - recall: 0.9917\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce4265a8-5ad9-432e-91b1-c8e18cfdd6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 1.5364 - accuracy: 0.6143 - recall: 0.6000\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c06ccf1-c466-4961-9cdc-296d7828dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa78c4-57d9-434d-b25a-ddbf4ef7c7eb",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0956f0e1-9f41-47de-b56d-5b551bea8b81",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0072 - accuracy: 0.9967 - recall: 0.9950\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0105 - accuracy: 0.9967 - recall: 0.9950\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0117 - accuracy: 0.9950 - recall: 0.9967\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0073 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0119 - accuracy: 0.9917 - recall: 0.9900\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0097 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0119 - accuracy: 0.9934 - recall: 0.9934\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0178 - accuracy: 0.9934 - recall: 0.9917\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0094 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0199 - accuracy: 0.9917 - recall: 0.9900\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0064 - accuracy: 0.9967 - recall: 0.9950\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0129 - accuracy: 0.9917 - recall: 0.9867\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0069 - accuracy: 0.9967 - recall: 0.9983\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0139 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0144 - accuracy: 0.9934 - recall: 0.9917\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0135 - accuracy: 0.9934 - recall: 0.9917\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0118 - accuracy: 0.9917 - recall: 0.9917\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0196 - accuracy: 0.9900 - recall: 0.9884\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0106 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0077 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0091 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0103 - accuracy: 0.9967 - recall: 0.9934\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0091 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0092 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0096 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0085 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0065 - accuracy: 0.9967 - recall: 0.9950\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0113 - accuracy: 0.9967 - recall: 0.9983\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0111 - accuracy: 0.9983 - recall: 0.9967\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0081 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 0.9967 - recall: 0.9983\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0147 - accuracy: 0.9917 - recall: 0.9900\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0068 - accuracy: 0.9983 - recall: 0.9967\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0055 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0044 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0101 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0108 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0070 - accuracy: 0.9967 - recall: 0.9983\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0048 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0040 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0096 - accuracy: 0.9967 - recall: 0.9950\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0103 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0059 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0106 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0056 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0099 - accuracy: 0.9950 - recall: 0.9900\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0142 - accuracy: 0.9917 - recall: 0.9917\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0042 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0117 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0088 - accuracy: 0.9934 - recall: 0.9934\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0074 - accuracy: 0.9983 - recall: 0.9950\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0061 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0077 - accuracy: 0.9983 - recall: 0.9967\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - recall: 0.9983\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0070 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0159 - accuracy: 0.9917 - recall: 0.9917\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0057 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0052 - accuracy: 0.9983 - recall: 0.9967\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0037 - accuracy: 1.0000 - recall: 0.9983\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0045 - accuracy: 0.9967 - recall: 0.9983\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0065 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0034 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0048 - accuracy: 1.0000 - recall: 0.9983\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0079 - accuracy: 0.9967 - recall: 0.9934\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0126 - accuracy: 0.9950 - recall: 0.9934\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0068 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0093 - accuracy: 0.9934 - recall: 0.9950\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0035 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0139 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0038 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0059 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0115 - accuracy: 0.9934 - recall: 0.9934\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0087 - accuracy: 0.9934 - recall: 0.9950\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0046 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0031 - accuracy: 0.9983 - recall: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0042 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0039 - accuracy: 0.9983 - recall: 0.9967\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - recall: 0.9983\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 0.9983 - recall: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - recall: 0.9983\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0046 - accuracy: 0.9983 - recall: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0071 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0065 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0068 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0120 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0030 - accuracy: 1.0000 - recall: 0.9983\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0042 - accuracy: 0.9967 - recall: 0.9950\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0098 - accuracy: 0.9950 - recall: 0.9950\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0036 - accuracy: 0.9983 - recall: 0.9950\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0075 - accuracy: 0.9950 - recall: 0.9967\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0030 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0031 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0128 - accuracy: 0.9967 - recall: 0.9967\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0033 - accuracy: 0.9983 - recall: 0.9983\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0037 - accuracy: 0.9983 - recall: 0.9983\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3792645a-b82d-42da-92ad-25053cf12627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 1.9330 - accuracy: 0.5821 - recall: 0.5786\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cdcfcfab-620b-407f-afdc-833cc42fcda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2832f-8489-41a7-b530-4bd194c81214",
   "metadata": {},
   "source": [
    "## Atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a054bdfa-3398-4d9d-840a-d3e69478eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[df_full['Target'] == 'Atheism']\n",
    "df_stance = df.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_sentiment = df.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf306a91-6ddf-4223-977f-6a9f38241fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df.Tweet)\n",
    "\n",
    "df_stance['Stance'] = le1.transform(df_stance['Stance'])\n",
    "df_sentiment['Sentiment'] = le2.transform(df_sentiment['Sentiment'])\n",
    "X_train = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_train_stance = df_stance.Stance.astype(np.int32)\n",
    "y_train_stance_ohe = keras.utils.to_categorical(y_train_stance, 3)\n",
    "y_train_sentiment = df_sentiment.Sentiment.astype(np.int32)\n",
    "y_train_sentiment_ohe = keras.utils.to_categorical(y_train_sentiment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01db4e91-37a7-4e77-99be-284bd2c06c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df_testing_full[df_testing_full['Target'] == 'Atheism']\n",
    "df_testing_stance = df_testing.drop(['ID','Opinion towards', 'Sentiment', 'Target'], axis=1)\n",
    "df_testing_sentiment = df_testing.drop(['ID','Opinion towards', 'Stance', 'Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd3cab6f-31cc-457c-9b4b-3ec1b00ce6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_testing.Tweet)\n",
    "df_testing_stance['Stance'] = le1.transform(df_testing_stance['Stance'])\n",
    "df_testing_sentiment['Sentiment'] = le2.transform(df_testing_sentiment['Sentiment'])\n",
    "\n",
    "X_test = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y_test_stance = df_testing_stance.Stance.astype(np.int32)\n",
    "y_test_stance_ohe = keras.utils.to_categorical(y_test_stance, 3)\n",
    "y_test_sentiment = df_testing_sentiment.Sentiment.astype(np.int32)\n",
    "y_test_sentiment_ohe = keras.utils.to_categorical(y_test_sentiment, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c97d5b-ae4e-4a2b-a9ef-60d6590b95d8",
   "metadata": {},
   "source": [
    "### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34c311b5-e803-4b61-a6eb-9294d7962cf5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.2955 - accuracy: 0.5887 - recall: 0.5634\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.9204 - accuracy: 0.6511 - recall: 0.6101\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.7235 - accuracy: 0.7018 - recall: 0.6725\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.6943 - accuracy: 0.7018 - recall: 0.6803\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5498 - accuracy: 0.7368 - recall: 0.7076\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4910 - accuracy: 0.7524 - recall: 0.7154\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5041 - accuracy: 0.7349 - recall: 0.7096\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4417 - accuracy: 0.7758 - recall: 0.7524\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4504 - accuracy: 0.7583 - recall: 0.7290\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3913 - accuracy: 0.7895 - recall: 0.7524\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3393 - accuracy: 0.8070 - recall: 0.7836\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2805 - accuracy: 0.8285 - recall: 0.8109\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2779 - accuracy: 0.8402 - recall: 0.8226\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2571 - accuracy: 0.8343 - recall: 0.8343\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2544 - accuracy: 0.8421 - recall: 0.8226\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2404 - accuracy: 0.8499 - recall: 0.8246\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2295 - accuracy: 0.8616 - recall: 0.8460\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2045 - accuracy: 0.8811 - recall: 0.8733\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.1963 - accuracy: 0.8772 - recall: 0.8694\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.1787 - accuracy: 0.9084 - recall: 0.8869\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.1389 - accuracy: 0.9181 - recall: 0.9181\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.1638 - accuracy: 0.9181 - recall: 0.9006\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.1295 - accuracy: 0.9318 - recall: 0.9045\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.1206 - accuracy: 0.9201 - recall: 0.9181\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.1210 - accuracy: 0.9415 - recall: 0.9084\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.1052 - accuracy: 0.9376 - recall: 0.9357\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0997 - accuracy: 0.9532 - recall: 0.9337\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0779 - accuracy: 0.9649 - recall: 0.9571\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0963 - accuracy: 0.9532 - recall: 0.9435\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.1143 - accuracy: 0.9513 - recall: 0.9337\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0782 - accuracy: 0.9571 - recall: 0.9532\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.1204 - accuracy: 0.9396 - recall: 0.9396\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0697 - accuracy: 0.9669 - recall: 0.9708\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0769 - accuracy: 0.9630 - recall: 0.9649\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0790 - accuracy: 0.9591 - recall: 0.9513\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0640 - accuracy: 0.9688 - recall: 0.9474\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0648 - accuracy: 0.9688 - recall: 0.9591\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0736 - accuracy: 0.9649 - recall: 0.9571\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0799 - accuracy: 0.9669 - recall: 0.9532\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0459 - accuracy: 0.9844 - recall: 0.9727\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0520 - accuracy: 0.9747 - recall: 0.9766\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0715 - accuracy: 0.9669 - recall: 0.9630\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0453 - accuracy: 0.9805 - recall: 0.9727\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0504 - accuracy: 0.9747 - recall: 0.9708\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0231 - accuracy: 0.9922 - recall: 0.9903\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0454 - accuracy: 0.9825 - recall: 0.9786\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0514 - accuracy: 0.9864 - recall: 0.9786\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0359 - accuracy: 0.9805 - recall: 0.9786\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0383 - accuracy: 0.9825 - recall: 0.9786\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0405 - accuracy: 0.9844 - recall: 0.9766\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0434 - accuracy: 0.9786 - recall: 0.9747\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0368 - accuracy: 0.9786 - recall: 0.9825\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0438 - accuracy: 0.9747 - recall: 0.9727\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0397 - accuracy: 0.9805 - recall: 0.9747\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0307 - accuracy: 0.9825 - recall: 0.9844\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0426 - accuracy: 0.9825 - recall: 0.9805\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0288 - accuracy: 0.9903 - recall: 0.9844\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0346 - accuracy: 0.9844 - recall: 0.9805\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0193 - accuracy: 0.9981 - recall: 0.9883\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 0.9981 - recall: 0.9942\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0186 - accuracy: 0.9903 - recall: 0.9903\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0209 - accuracy: 0.9903 - recall: 0.9903\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0124 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0093 - accuracy: 0.9961 - recall: 0.9981\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0172 - accuracy: 0.9922 - recall: 0.9883\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0248 - accuracy: 0.9864 - recall: 0.9825\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0148 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0183 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0176 - accuracy: 0.9961 - recall: 0.9883\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0095 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0070 - accuracy: 1.0000 - recall: 0.9961\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0193 - accuracy: 0.9922 - recall: 0.9864\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0285 - accuracy: 0.9825 - recall: 0.9825\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0142 - accuracy: 0.9961 - recall: 0.9922\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.0063 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0179 - accuracy: 0.9883 - recall: 0.9903\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0173 - accuracy: 0.9883 - recall: 0.9883\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0076 - accuracy: 0.9981 - recall: 0.9942\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0156 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0348 - accuracy: 0.9805 - recall: 0.9844\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0078 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0306 - accuracy: 0.9844 - recall: 0.9844\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0181 - accuracy: 0.9903 - recall: 0.9903\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0172 - accuracy: 0.9903 - recall: 0.9903\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0184 - accuracy: 0.9883 - recall: 0.9883\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0103 - accuracy: 0.9942 - recall: 0.9961\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0133 - accuracy: 0.9942 - recall: 0.9922\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0107 - accuracy: 0.9942 - recall: 0.9922\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0132 - accuracy: 0.9942 - recall: 0.9961\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0189 - accuracy: 0.9922 - recall: 0.9883\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0061 - accuracy: 1.0000 - recall: 0.9981\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0076 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0087 - accuracy: 0.9942 - recall: 0.9961\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0203 - accuracy: 0.9942 - recall: 0.9903\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0115 - accuracy: 0.9961 - recall: 0.9922\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0052 - accuracy: 1.0000 - recall: 0.9981\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0189 - accuracy: 0.9903 - recall: 0.9883\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0130 - accuracy: 0.9942 - recall: 0.9922\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0068 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0121 - accuracy: 0.9942 - recall: 0.9903\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1032cef-d45f-402f-8526-3fae1b551776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9392 - accuracy: 0.7227 - recall: 0.7136\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "000d1e4e-1c96-44fe-8341-681a5d04c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f97439-0ac8-40cd-a75b-54d034ea0721",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "099ad8aa-9a5c-4df0-ba93-b348d108f8d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0111 - accuracy: 0.9922 - recall: 0.9903\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0102 - accuracy: 0.9942 - recall: 0.9961\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0097 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0100 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0085 - accuracy: 0.9942 - recall: 0.9942\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0144 - accuracy: 0.9903 - recall: 0.9922\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0122 - accuracy: 0.9903 - recall: 0.9903\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0067 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0102 - accuracy: 0.9961 - recall: 0.9981\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0078 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0112 - accuracy: 0.9942 - recall: 0.9942\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0208 - accuracy: 0.9903 - recall: 0.9883\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0088 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0077 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0068 - accuracy: 0.9961 - recall: 0.9981\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0083 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0078 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.0102 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0133 - accuracy: 0.9922 - recall: 0.9922\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0054 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0072 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0082 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0052 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0112 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0080 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0072 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0026 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0065 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0036 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0036 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0099 - accuracy: 0.9942 - recall: 0.9961\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0051 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0030 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0085 - accuracy: 0.9961 - recall: 0.9981\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0057 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0095 - accuracy: 0.9942 - recall: 0.9961\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0128 - accuracy: 0.9942 - recall: 0.9922\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0052 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0070 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0038 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0055 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0168 - accuracy: 0.9903 - recall: 0.9903\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0027 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0100 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0040 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0053 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0024 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0038 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0119 - accuracy: 0.9942 - recall: 0.9942\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0045 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0029 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0081 - accuracy: 0.9942 - recall: 0.9922\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.7672e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 0.9981 - recall: 1.0000\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0031 - accuracy: 0.9981 - recall: 1.0000\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0038 - accuracy: 1.0000 - recall: 0.9981\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0044 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0075 - accuracy: 0.9942 - recall: 0.9981\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0091 - accuracy: 0.9961 - recall: 0.9942\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0024 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0019 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - recall: 0.9981\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 1.0000 - recall: 0.9981\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.0730e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.7966e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0046 - accuracy: 0.9981 - recall: 0.9961\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.6370e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0049 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0089 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.8020e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0010 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0026 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - recall: 0.9981\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0097 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0025 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 0.9981 - recall: 0.9981\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 5.7411e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0054 - accuracy: 0.9961 - recall: 0.9961\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 5.1521e-04 - accuracy: 1.0000 - recall: 1.0000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = gru.fit(X_train, y_train_stance_ohe, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99e127e8-7b11-4212-b05b-35d29f9bdece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1632 - accuracy: 0.7409 - recall: 0.7409\n"
     ]
    }
   ],
   "source": [
    "scores = gru.evaluate(X_test, y_test_stance_ohe, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11033ae5-63cc-4390-9a90-023ce97c731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gru.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3934e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "  \n",
    "import re\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
